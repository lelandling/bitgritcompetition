{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuk_ceUvs8oz"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn import datasets\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GHCmzlqt9B8"
      },
      "source": [
        "Data exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhpZJVFqs_3X"
      },
      "outputs": [],
      "source": [
        "traindf = pd.read_csv(\"train.csv\")\n",
        "testdf = pd.read_csv(\"test.csv\")\n",
        "solexample = pd.read_csv(\"solution_format.csv\")\n",
        "trainlabels = traindf['labels']\n",
        "traindata = traindf.iloc[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WturW2gKiG2G"
      },
      "outputs": [],
      "source": [
        "solexample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "AaMcGTNCvLF0",
        "outputId": "f41a9903-3bb6-42b8-f171-230d2eb827a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5616773b-d378-4f32-81f0-4e06886a75d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.033875</td>\n",
              "      <td>0.978446</td>\n",
              "      <td>-0.142131</td>\n",
              "      <td>-0.177117</td>\n",
              "      <td>-1.470684</td>\n",
              "      <td>1.669562</td>\n",
              "      <td>-0.196530</td>\n",
              "      <td>-0.125239</td>\n",
              "      <td>-0.452284</td>\n",
              "      <td>-0.128052</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.111266</td>\n",
              "      <td>0.716084</td>\n",
              "      <td>0.060039</td>\n",
              "      <td>0.301279</td>\n",
              "      <td>-1.174846</td>\n",
              "      <td>-1.076498</td>\n",
              "      <td>-0.069452</td>\n",
              "      <td>-0.604012</td>\n",
              "      <td>-2.179176</td>\n",
              "      <td>0.558003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.348835</td>\n",
              "      <td>0.294815</td>\n",
              "      <td>-0.557577</td>\n",
              "      <td>-2.020773</td>\n",
              "      <td>-1.234715</td>\n",
              "      <td>1.633930</td>\n",
              "      <td>-1.680658</td>\n",
              "      <td>-0.358146</td>\n",
              "      <td>0.166122</td>\n",
              "      <td>-1.656990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.735240</td>\n",
              "      <td>0.829781</td>\n",
              "      <td>1.521941</td>\n",
              "      <td>1.347946</td>\n",
              "      <td>0.754505</td>\n",
              "      <td>1.330642</td>\n",
              "      <td>-0.754453</td>\n",
              "      <td>0.582956</td>\n",
              "      <td>0.252671</td>\n",
              "      <td>1.495870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.113248</td>\n",
              "      <td>-0.607726</td>\n",
              "      <td>-0.947791</td>\n",
              "      <td>0.830851</td>\n",
              "      <td>0.998291</td>\n",
              "      <td>0.498321</td>\n",
              "      <td>-1.493958</td>\n",
              "      <td>0.789572</td>\n",
              "      <td>-1.311018</td>\n",
              "      <td>0.848524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104698</td>\n",
              "      <td>0.616189</td>\n",
              "      <td>-1.035953</td>\n",
              "      <td>2.111387</td>\n",
              "      <td>-0.984415</td>\n",
              "      <td>1.148076</td>\n",
              "      <td>-1.433554</td>\n",
              "      <td>0.243372</td>\n",
              "      <td>0.170083</td>\n",
              "      <td>1.274795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.223321</td>\n",
              "      <td>-0.479048</td>\n",
              "      <td>-1.925789</td>\n",
              "      <td>1.680377</td>\n",
              "      <td>0.021840</td>\n",
              "      <td>-1.453307</td>\n",
              "      <td>0.605559</td>\n",
              "      <td>-0.019024</td>\n",
              "      <td>1.065448</td>\n",
              "      <td>0.717341</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360237</td>\n",
              "      <td>-1.957863</td>\n",
              "      <td>-0.123384</td>\n",
              "      <td>1.505329</td>\n",
              "      <td>0.660290</td>\n",
              "      <td>-1.769443</td>\n",
              "      <td>-0.547756</td>\n",
              "      <td>-0.568122</td>\n",
              "      <td>0.244645</td>\n",
              "      <td>0.982116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.160109</td>\n",
              "      <td>0.422684</td>\n",
              "      <td>-0.308029</td>\n",
              "      <td>0.227744</td>\n",
              "      <td>0.432854</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.193832</td>\n",
              "      <td>1.035091</td>\n",
              "      <td>-0.538868</td>\n",
              "      <td>0.778445</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416629</td>\n",
              "      <td>1.441766</td>\n",
              "      <td>0.212572</td>\n",
              "      <td>-0.994721</td>\n",
              "      <td>1.143999</td>\n",
              "      <td>-2.166923</td>\n",
              "      <td>-1.199248</td>\n",
              "      <td>-1.028636</td>\n",
              "      <td>0.752791</td>\n",
              "      <td>0.317169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5245</th>\n",
              "      <td>1.157565</td>\n",
              "      <td>-0.142219</td>\n",
              "      <td>1.043992</td>\n",
              "      <td>1.144946</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>0.248978</td>\n",
              "      <td>-1.505100</td>\n",
              "      <td>-0.874137</td>\n",
              "      <td>-1.782724</td>\n",
              "      <td>0.261597</td>\n",
              "      <td>...</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.255793</td>\n",
              "      <td>-0.154838</td>\n",
              "      <td>0.413029</td>\n",
              "      <td>-0.482939</td>\n",
              "      <td>-1.277953</td>\n",
              "      <td>-0.445082</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.924614</td>\n",
              "      <td>-0.432462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5246</th>\n",
              "      <td>1.424709</td>\n",
              "      <td>0.235910</td>\n",
              "      <td>1.356778</td>\n",
              "      <td>1.368099</td>\n",
              "      <td>-0.318862</td>\n",
              "      <td>1.039765</td>\n",
              "      <td>-0.986854</td>\n",
              "      <td>-0.330184</td>\n",
              "      <td>-1.383120</td>\n",
              "      <td>1.243559</td>\n",
              "      <td>...</td>\n",
              "      <td>1.424709</td>\n",
              "      <td>-1.066107</td>\n",
              "      <td>0.881258</td>\n",
              "      <td>-0.488691</td>\n",
              "      <td>-1.281223</td>\n",
              "      <td>-1.213291</td>\n",
              "      <td>0.122692</td>\n",
              "      <td>1.175627</td>\n",
              "      <td>-1.145360</td>\n",
              "      <td>0.451026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5247</th>\n",
              "      <td>-0.375687</td>\n",
              "      <td>1.524455</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>-0.007917</td>\n",
              "      <td>0.073809</td>\n",
              "      <td>-0.906909</td>\n",
              "      <td>-1.254247</td>\n",
              "      <td>1.606182</td>\n",
              "      <td>0.298557</td>\n",
              "      <td>0.053378</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028349</td>\n",
              "      <td>-0.968204</td>\n",
              "      <td>-1.233815</td>\n",
              "      <td>1.626613</td>\n",
              "      <td>-0.191802</td>\n",
              "      <td>1.115823</td>\n",
              "      <td>0.380284</td>\n",
              "      <td>-0.293960</td>\n",
              "      <td>0.135104</td>\n",
              "      <td>1.381434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5248</th>\n",
              "      <td>-0.478238</td>\n",
              "      <td>1.666142</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-0.362771</td>\n",
              "      <td>1.798104</td>\n",
              "      <td>-0.214314</td>\n",
              "      <td>0.775400</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>0.725914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-1.121552</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>-0.593705</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>1.765114</td>\n",
              "      <td>0.313533</td>\n",
              "      <td>-0.329781</td>\n",
              "      <td>-1.220524</td>\n",
              "      <td>0.033114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5249</th>\n",
              "      <td>-0.750874</td>\n",
              "      <td>0.267008</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.179867</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.279173</td>\n",
              "      <td>1.731765</td>\n",
              "      <td>0.564925</td>\n",
              "      <td>1.508328</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.850180</td>\n",
              "      <td>0.937321</td>\n",
              "      <td>-1.594972</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>1.582807</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>-0.254346</td>\n",
              "      <td>0.664230</td>\n",
              "      <td>1.831071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5250 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5616773b-d378-4f32-81f0-4e06886a75d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5616773b-d378-4f32-81f0-4e06886a75d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5616773b-d378-4f32-81f0-4e06886a75d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "0    -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562 -0.196530   \n",
              "1    -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930 -1.680658   \n",
              "2     0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321 -1.493958   \n",
              "3     1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307  0.605559   \n",
              "4     0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348  0.193832   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5245  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978 -1.505100   \n",
              "5246  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765 -0.986854   \n",
              "5247 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909 -1.254247   \n",
              "5248 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104 -0.214314   \n",
              "5249 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999 -0.279173   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "0    -0.125239 -0.452284 -0.128052  ... -1.111266  0.716084  0.060039   \n",
              "1    -0.358146  0.166122 -1.656990  ...  0.735240  0.829781  1.521941   \n",
              "2     0.789572 -1.311018  0.848524  ...  0.104698  0.616189 -1.035953   \n",
              "3    -0.019024  1.065448  0.717341  ...  0.360237 -1.957863 -0.123384   \n",
              "4     1.035091 -0.538868  0.778445  ...  0.416629  1.441766  0.212572   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5245 -0.874137 -1.782724  0.261597  ...  1.195423 -0.255793 -0.154838   \n",
              "5246 -0.330184 -1.383120  1.243559  ...  1.424709 -1.066107  0.881258   \n",
              "5247  1.606182  0.298557  0.053378  ... -0.028349 -0.968204 -1.233815   \n",
              "5248  0.775400 -0.379267  0.725914  ... -0.428752 -1.121552 -0.379267   \n",
              "5249  1.731765  0.564925  1.508328  ... -0.303999 -0.850180  0.937321   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0     0.301279 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
              "1     1.347946  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
              "2     2.111387 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
              "3     1.505329  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
              "4    -0.994721  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "5245  0.413029 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462  \n",
              "5246 -0.488691 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026  \n",
              "5247  1.626613 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434  \n",
              "5248 -0.593705  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114  \n",
              "5249 -1.594972  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071  \n",
              "\n",
              "[5250 rows x 1200 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "traindata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "LMU4MWaF_0mH",
        "outputId": "efc38180-8cfe-4b8a-ee41-5d33b2f40437"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e80cc2a0-dcaf-4152-97d0-b829f429a878\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-2.033875</td>\n",
              "      <td>0.978446</td>\n",
              "      <td>-0.142131</td>\n",
              "      <td>-0.177117</td>\n",
              "      <td>-1.470684</td>\n",
              "      <td>1.669562</td>\n",
              "      <td>-0.196530</td>\n",
              "      <td>-0.125239</td>\n",
              "      <td>-0.452284</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.111266</td>\n",
              "      <td>0.716084</td>\n",
              "      <td>0.060039</td>\n",
              "      <td>0.301279</td>\n",
              "      <td>-1.174846</td>\n",
              "      <td>-1.076498</td>\n",
              "      <td>-0.069452</td>\n",
              "      <td>-0.604012</td>\n",
              "      <td>-2.179176</td>\n",
              "      <td>0.558003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.348835</td>\n",
              "      <td>0.294815</td>\n",
              "      <td>-0.557577</td>\n",
              "      <td>-2.020773</td>\n",
              "      <td>-1.234715</td>\n",
              "      <td>1.633930</td>\n",
              "      <td>-1.680658</td>\n",
              "      <td>-0.358146</td>\n",
              "      <td>0.166122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.735240</td>\n",
              "      <td>0.829781</td>\n",
              "      <td>1.521941</td>\n",
              "      <td>1.347946</td>\n",
              "      <td>0.754505</td>\n",
              "      <td>1.330642</td>\n",
              "      <td>-0.754453</td>\n",
              "      <td>0.582956</td>\n",
              "      <td>0.252671</td>\n",
              "      <td>1.495870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.113248</td>\n",
              "      <td>-0.607726</td>\n",
              "      <td>-0.947791</td>\n",
              "      <td>0.830851</td>\n",
              "      <td>0.998291</td>\n",
              "      <td>0.498321</td>\n",
              "      <td>-1.493958</td>\n",
              "      <td>0.789572</td>\n",
              "      <td>-1.311018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104698</td>\n",
              "      <td>0.616189</td>\n",
              "      <td>-1.035953</td>\n",
              "      <td>2.111387</td>\n",
              "      <td>-0.984415</td>\n",
              "      <td>1.148076</td>\n",
              "      <td>-1.433554</td>\n",
              "      <td>0.243372</td>\n",
              "      <td>0.170083</td>\n",
              "      <td>1.274795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1.223321</td>\n",
              "      <td>-0.479048</td>\n",
              "      <td>-1.925789</td>\n",
              "      <td>1.680377</td>\n",
              "      <td>0.021840</td>\n",
              "      <td>-1.453307</td>\n",
              "      <td>0.605559</td>\n",
              "      <td>-0.019024</td>\n",
              "      <td>1.065448</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360237</td>\n",
              "      <td>-1.957863</td>\n",
              "      <td>-0.123384</td>\n",
              "      <td>1.505329</td>\n",
              "      <td>0.660290</td>\n",
              "      <td>-1.769443</td>\n",
              "      <td>-0.547756</td>\n",
              "      <td>-0.568122</td>\n",
              "      <td>0.244645</td>\n",
              "      <td>0.982116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.160109</td>\n",
              "      <td>0.422684</td>\n",
              "      <td>-0.308029</td>\n",
              "      <td>0.227744</td>\n",
              "      <td>0.432854</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.193832</td>\n",
              "      <td>1.035091</td>\n",
              "      <td>-0.538868</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416629</td>\n",
              "      <td>1.441766</td>\n",
              "      <td>0.212572</td>\n",
              "      <td>-0.994721</td>\n",
              "      <td>1.143999</td>\n",
              "      <td>-2.166923</td>\n",
              "      <td>-1.199248</td>\n",
              "      <td>-1.028636</td>\n",
              "      <td>0.752791</td>\n",
              "      <td>0.317169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5245</th>\n",
              "      <td>0</td>\n",
              "      <td>1.157565</td>\n",
              "      <td>-0.142219</td>\n",
              "      <td>1.043992</td>\n",
              "      <td>1.144946</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>0.248978</td>\n",
              "      <td>-1.505100</td>\n",
              "      <td>-0.874137</td>\n",
              "      <td>-1.782724</td>\n",
              "      <td>...</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.255793</td>\n",
              "      <td>-0.154838</td>\n",
              "      <td>0.413029</td>\n",
              "      <td>-0.482939</td>\n",
              "      <td>-1.277953</td>\n",
              "      <td>-0.445082</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.924614</td>\n",
              "      <td>-0.432462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5246</th>\n",
              "      <td>0</td>\n",
              "      <td>1.424709</td>\n",
              "      <td>0.235910</td>\n",
              "      <td>1.356778</td>\n",
              "      <td>1.368099</td>\n",
              "      <td>-0.318862</td>\n",
              "      <td>1.039765</td>\n",
              "      <td>-0.986854</td>\n",
              "      <td>-0.330184</td>\n",
              "      <td>-1.383120</td>\n",
              "      <td>...</td>\n",
              "      <td>1.424709</td>\n",
              "      <td>-1.066107</td>\n",
              "      <td>0.881258</td>\n",
              "      <td>-0.488691</td>\n",
              "      <td>-1.281223</td>\n",
              "      <td>-1.213291</td>\n",
              "      <td>0.122692</td>\n",
              "      <td>1.175627</td>\n",
              "      <td>-1.145360</td>\n",
              "      <td>0.451026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5247</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.375687</td>\n",
              "      <td>1.524455</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>-0.007917</td>\n",
              "      <td>0.073809</td>\n",
              "      <td>-0.906909</td>\n",
              "      <td>-1.254247</td>\n",
              "      <td>1.606182</td>\n",
              "      <td>0.298557</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028349</td>\n",
              "      <td>-0.968204</td>\n",
              "      <td>-1.233815</td>\n",
              "      <td>1.626613</td>\n",
              "      <td>-0.191802</td>\n",
              "      <td>1.115823</td>\n",
              "      <td>0.380284</td>\n",
              "      <td>-0.293960</td>\n",
              "      <td>0.135104</td>\n",
              "      <td>1.381434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5248</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.478238</td>\n",
              "      <td>1.666142</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-0.362771</td>\n",
              "      <td>1.798104</td>\n",
              "      <td>-0.214314</td>\n",
              "      <td>0.775400</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-1.121552</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>-0.593705</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>1.765114</td>\n",
              "      <td>0.313533</td>\n",
              "      <td>-0.329781</td>\n",
              "      <td>-1.220524</td>\n",
              "      <td>0.033114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5249</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.750874</td>\n",
              "      <td>0.267008</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.179867</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.279173</td>\n",
              "      <td>1.731765</td>\n",
              "      <td>0.564925</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.850180</td>\n",
              "      <td>0.937321</td>\n",
              "      <td>-1.594972</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>1.582807</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>-0.254346</td>\n",
              "      <td>0.664230</td>\n",
              "      <td>1.831071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5250 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e80cc2a0-dcaf-4152-97d0-b829f429a878')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e80cc2a0-dcaf-4152-97d0-b829f429a878 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e80cc2a0-dcaf-4152-97d0-b829f429a878');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      labels       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
              "0          0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562   \n",
              "1          1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
              "2          1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
              "3          0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
              "4          0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "5245       0  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978   \n",
              "5246       0  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765   \n",
              "5247       1 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909   \n",
              "5248       1 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104   \n",
              "5249       1 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999   \n",
              "\n",
              "           f_6       f_7       f_8  ...    f_1190    f_1191    f_1192  \\\n",
              "0    -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039   \n",
              "1    -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941   \n",
              "2    -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953   \n",
              "3     0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384   \n",
              "4     0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5245 -1.505100 -0.874137 -1.782724  ...  1.195423 -0.255793 -0.154838   \n",
              "5246 -0.986854 -0.330184 -1.383120  ...  1.424709 -1.066107  0.881258   \n",
              "5247 -1.254247  1.606182  0.298557  ... -0.028349 -0.968204 -1.233815   \n",
              "5248 -0.214314  0.775400 -0.379267  ... -0.428752 -1.121552 -0.379267   \n",
              "5249 -0.279173  1.731765  0.564925  ... -0.303999 -0.850180  0.937321   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0     0.301279 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
              "1     1.347946  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
              "2     2.111387 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
              "3     1.505329  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
              "4    -0.994721  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "5245  0.413029 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462  \n",
              "5246 -0.488691 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026  \n",
              "5247  1.626613 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434  \n",
              "5248 -0.593705  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114  \n",
              "5249 -1.594972  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071  \n",
              "\n",
              "[5250 rows x 1201 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "traindf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpjC0xFut-Ub",
        "outputId": "ab227184-8a5c-4552-b24a-a4b37af4dbdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "labels    0.266667\n",
              "f_0       0.385453\n",
              "f_1       0.086769\n",
              "f_2       0.317084\n",
              "f_3       0.400414\n",
              "            ...   \n",
              "f_1195   -0.156475\n",
              "f_1196   -0.096026\n",
              "f_1197    0.372260\n",
              "f_1198   -0.222551\n",
              "f_1199    0.006532\n",
              "Length: 1201, dtype: float64"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "traindf.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy1NvfpFuALB"
      },
      "outputs": [],
      "source": [
        "#add flipped data\n",
        "\n",
        "flipped_df = traindf.iloc[:, 0:1].join(traindf.iloc[:, 1:][::-1])\n",
        "\n",
        "aug_df = pd.concat([traindf, flipped_df], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHv1Y8ZbOBKe"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = traindata\n",
        "y = trainlabels\n",
        "ay = aug_df['labels']\n",
        "aX = aug_df.iloc[:, 1:]\n",
        "\n",
        "\n",
        "# X = traindata.iloc[:, importantfeatures]\n",
        "# y = trainlabels\n",
        "# ay = aug_df['labels']\n",
        "# aX = aug_df.iloc[:, 1:]\n",
        "# aX = aX.iloc[:, importantfeatures]\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "aX_train, aX_test, ay_train, ay_test = train_test_split(aX, ay, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQAy_1FuaRc"
      },
      "source": [
        "Testing Classical methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmBjBsteYNdZ",
        "outputId": "61f6cb64-5a96-4415-f2a2-d2962c962c56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['f_0', 'f_1', 'f_2', 'f_3', 'f_4', 'f_6', 'f_7', 'f_8', 'f_9', 'f_11',\n",
              "       ...\n",
              "       'f_1182', 'f_1183', 'f_1186', 'f_1187', 'f_1191', 'f_1192', 'f_1193',\n",
              "       'f_1194', 'f_1196', 'f_1197'],\n",
              "      dtype='object', length=717)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aX.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "VFObsUDiYfam",
        "outputId": "7463520b-b080-4e17-b233-dd521b9582d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e5b6c3de-93f6-48a9-b353-91bd30bcffa6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_10</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1181</th>\n",
              "      <th>f_1182</th>\n",
              "      <th>f_1185</th>\n",
              "      <th>f_1186</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>-1.485896</td>\n",
              "      <td>...</td>\n",
              "      <td>0.752675</td>\n",
              "      <td>-1.077703</td>\n",
              "      <td>1.431924</td>\n",
              "      <td>-0.013587</td>\n",
              "      <td>-0.776403</td>\n",
              "      <td>-0.662884</td>\n",
              "      <td>-0.257091</td>\n",
              "      <td>-1.168413</td>\n",
              "      <td>-0.482520</td>\n",
              "      <td>-0.085453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>-0.099658</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>0.505176</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.298254</td>\n",
              "      <td>0.100701</td>\n",
              "      <td>0.605404</td>\n",
              "      <td>0.065069</td>\n",
              "      <td>0.379635</td>\n",
              "      <td>-1.760084</td>\n",
              "      <td>1.125450</td>\n",
              "      <td>-0.328047</td>\n",
              "      <td>-1.257607</td>\n",
              "      <td>0.964312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>0.224159</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.403457</td>\n",
              "      <td>-2.438368</td>\n",
              "      <td>0.089148</td>\n",
              "      <td>-0.205051</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.373589</td>\n",
              "      <td>-0.483701</td>\n",
              "      <td>-0.964782</td>\n",
              "      <td>0.066040</td>\n",
              "      <td>-0.444567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>1.226839</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>-0.391189</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137612</td>\n",
              "      <td>0.362197</td>\n",
              "      <td>-0.637794</td>\n",
              "      <td>0.524736</td>\n",
              "      <td>-0.442288</td>\n",
              "      <td>-2.794472</td>\n",
              "      <td>-0.763468</td>\n",
              "      <td>-0.789832</td>\n",
              "      <td>-2.703150</td>\n",
              "      <td>-2.058728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>0.518777</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>-0.019973</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.904386</td>\n",
              "      <td>-0.383635</td>\n",
              "      <td>-1.709187</td>\n",
              "      <td>-0.296326</td>\n",
              "      <td>-2.624450</td>\n",
              "      <td>-3.200223</td>\n",
              "      <td>0.711422</td>\n",
              "      <td>-0.190394</td>\n",
              "      <td>-1.656639</td>\n",
              "      <td>0.707360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>2246</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.319077</td>\n",
              "      <td>0.849589</td>\n",
              "      <td>0.822723</td>\n",
              "      <td>0.325704</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.910127</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.574303</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.493706</td>\n",
              "      <td>0.836156</td>\n",
              "      <td>-1.272816</td>\n",
              "      <td>0.016746</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-2.226556</td>\n",
              "      <td>-0.090717</td>\n",
              "      <td>-1.393713</td>\n",
              "      <td>-0.399675</td>\n",
              "      <td>-0.856395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>2247</td>\n",
              "      <td>1.005737</td>\n",
              "      <td>-0.064755</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>0.724028</td>\n",
              "      <td>0.712760</td>\n",
              "      <td>-0.785929</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>-1.101443</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.729587</td>\n",
              "      <td>1.129689</td>\n",
              "      <td>-1.619786</td>\n",
              "      <td>0.757833</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.270468</td>\n",
              "      <td>-0.932417</td>\n",
              "      <td>-1.169053</td>\n",
              "      <td>-0.605636</td>\n",
              "      <td>-0.323927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>2248</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>1.223561</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.987156</td>\n",
              "      <td>-0.003031</td>\n",
              "      <td>-1.158309</td>\n",
              "      <td>1.237823</td>\n",
              "      <td>-1.272410</td>\n",
              "      <td>-1.029945</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.031556</td>\n",
              "      <td>-1.429300</td>\n",
              "      <td>-0.245497</td>\n",
              "      <td>1.009620</td>\n",
              "      <td>0.581740</td>\n",
              "      <td>-1.386512</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>-1.243885</td>\n",
              "      <td>-0.630589</td>\n",
              "      <td>1.594391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>2249</td>\n",
              "      <td>1.042624</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.066538</td>\n",
              "      <td>1.030667</td>\n",
              "      <td>0.707827</td>\n",
              "      <td>-1.396612</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-1.025944</td>\n",
              "      <td>-0.224822</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.205300</td>\n",
              "      <td>0.970882</td>\n",
              "      <td>-0.404178</td>\n",
              "      <td>0.588257</td>\n",
              "      <td>1.078495</td>\n",
              "      <td>-1.193343</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>-0.081338</td>\n",
              "      <td>-0.368307</td>\n",
              "      <td>-0.129166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>2250</td>\n",
              "      <td>-1.319572</td>\n",
              "      <td>-0.485173</td>\n",
              "      <td>-0.098500</td>\n",
              "      <td>2.323293</td>\n",
              "      <td>-0.953250</td>\n",
              "      <td>0.084661</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>1.427840</td>\n",
              "      <td>0.450983</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.011513</td>\n",
              "      <td>0.003256</td>\n",
              "      <td>-0.688685</td>\n",
              "      <td>-0.179905</td>\n",
              "      <td>-0.505524</td>\n",
              "      <td>-0.220607</td>\n",
              "      <td>-0.871845</td>\n",
              "      <td>0.654495</td>\n",
              "      <td>-0.444470</td>\n",
              "      <td>-0.118851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 717 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5b6c3de-93f6-48a9-b353-91bd30bcffa6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5b6c3de-93f6-48a9-b353-91bd30bcffa6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5b6c3de-93f6-48a9-b353-91bd30bcffa6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id       f_0       f_1       f_2       f_3       f_5       f_6  \\\n",
              "0        1 -3.388242  0.868285 -0.427619 -0.678964  0.262761  1.243040   \n",
              "1        2 -0.496920  0.952381  0.989040  0.451422 -0.099658 -1.124326   \n",
              "2        3  1.128369 -0.537951  2.544358  1.165254  0.776961 -0.495768   \n",
              "3        4  0.051253  1.746814  0.681177  1.844524  1.226839 -0.085519   \n",
              "4        5  1.423209 -0.983594 -1.694170  1.197507  0.518777 -0.298612   \n",
              "...    ...       ...       ...       ...       ...       ...       ...   \n",
              "2245  2246  0.889888 -0.319077  0.849589  0.822723  0.325704  0.876455   \n",
              "2246  2247  1.005737 -0.064755  1.163494  1.163494  0.724028  0.712760   \n",
              "2247  2248  1.252086  1.223561  0.153859 -0.987156 -0.003031 -1.158309   \n",
              "2248  2249  1.042624 -0.129166  1.066538  1.030667  0.707827 -1.396612   \n",
              "2249  2250 -1.319572 -0.485173 -0.098500  2.323293 -0.953250  0.084661   \n",
              "\n",
              "           f_7       f_8      f_10  ...    f_1181    f_1182    f_1185  \\\n",
              "0     1.537751 -0.352028 -1.485896  ...  0.752675 -1.077703  1.431924   \n",
              "1     0.729430 -0.216224  0.505176  ... -1.298254  0.100701  0.605404   \n",
              "2     0.060111 -1.418468  0.224159  ... -1.403457 -2.438368  0.089148   \n",
              "3     0.379008 -1.003667 -0.391189  ...  0.137612  0.362197 -0.637794   \n",
              "4    -0.365174  0.738447 -0.019973  ... -0.904386 -0.383635 -1.709187   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2245 -0.910127  0.889888 -0.574303  ... -0.493706  0.836156 -1.272816   \n",
              "2246 -0.785929 -1.225394 -1.101443  ... -0.729587  1.129689 -1.619786   \n",
              "2247  1.237823 -1.272410 -1.029945  ... -0.031556 -1.429300 -0.245497   \n",
              "2248  0.014319 -1.025944 -0.224822  ... -1.205300  0.970882 -0.404178   \n",
              "2249 -0.566577  1.427840  0.450983  ... -2.011513  0.003256 -0.688685   \n",
              "\n",
              "        f_1186    f_1190    f_1191    f_1192    f_1193    f_1195    f_1196  \n",
              "0    -0.013587 -0.776403 -0.662884 -0.257091 -1.168413 -0.482520 -0.085453  \n",
              "1     0.065069  0.379635 -1.760084  1.125450 -0.328047 -1.257607  0.964312  \n",
              "2    -0.205051  1.165254 -1.373589 -0.483701 -0.964782  0.066040 -0.444567  \n",
              "3     0.524736 -0.442288 -2.794472 -0.763468 -0.789832 -2.703150 -2.058728  \n",
              "4    -0.296326 -2.624450 -3.200223  0.711422 -0.190394 -1.656639  0.707360  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2245  0.016746  0.889888 -2.226556 -0.090717 -1.393713 -0.399675 -0.856395  \n",
              "2246  0.757833  1.163494 -1.270468 -0.932417 -1.169053 -0.605636 -0.323927  \n",
              "2247  1.009620  0.581740 -1.386512  0.809943 -1.243885 -0.630589  1.594391  \n",
              "2248  0.588257  1.078495 -1.193343  0.086061 -0.081338 -0.368307 -0.129166  \n",
              "2249 -0.179905 -0.505524 -0.220607 -0.871845  0.654495 -0.444470 -0.118851  \n",
              "\n",
              "[2250 rows x 717 columns]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOGxbnnvTqhI"
      },
      "outputs": [],
      "source": [
        "aX = aug_df.iloc[:, 1:]\n",
        "y  = aug_df['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "biCF4JDaRIZh",
        "outputId": "50e8fdc8-c14e-4b48-a12d-8170ca4eb092"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#create feature importance using LR\n",
        "LRmodel = LogisticRegression()\n",
        "\n",
        "LRmodel.fit(aX, y)\n",
        "\n",
        "# get importance\n",
        "importance = LRmodel.coef_[0]\n",
        "# summarize feature importance\n",
        "# for i,v in enumerate(importance):\n",
        "# \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.show()\n",
        "\n",
        "# y_pred = LRmodel.predict(X_test)\n",
        "# # Evaluate the model\n",
        "# accuracy = accuracy_score(y_test, y_pred)  # For classification tasks\n",
        "# print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "DRWMvuTodL3n",
        "outputId": "8ffa85e2-4add-48eb-c691-ed9542648e12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=150)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestRegressor(n_estimators=150)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf = RandomForestRegressor(n_estimators=150)\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "kiedKzAxejSM",
        "outputId": "4fe3f647-3fec-44f8-9a3a-547fda6f51cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Feature Importance')"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sort = rf.feature_importances_.argsort()\n",
        "\n",
        "pyplot.barh(X.columns, rf.feature_importances_)\n",
        "pyplot.xlabel(\"Feature Importance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZgp86p8R1sB"
      },
      "outputs": [],
      "source": [
        "importantfeatures = []\n",
        "reallyimportantfeatures = []\n",
        "for i,v in enumerate(importance):\n",
        "    if v >= .1 or v <= -0.1:\n",
        "        # print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "        importantfeatures.append(i)\n",
        "    if v >= .2 or v <= -0.2:\n",
        "      # print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "        reallyimportantfeatures.append(i)\n",
        "\n",
        "# reducedaX = aX.iloc[:, importantfeatures]\n",
        "# reducedaX = aX.iloc[:, importantfeatures]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeUtHdRBVrfK"
      },
      "outputs": [],
      "source": [
        "# xgbClassifier.predict()\n",
        "testdf['labels'] = xgbClassifier.predict(testdf.iloc[:, 1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAVPI9bvWVtD"
      },
      "outputs": [],
      "source": [
        "submission = testdf[['id', 'labels']]\n",
        "submission.to_csv(\"xgboost_waug.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9O0u5UPAptw",
        "outputId": "68386040-33c9-4237-a8c4-91df5ea154cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8714285714285714\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the XGBoost model\n",
        "xgbClassifier = xgb.XGBClassifier()  # For classification tasks\n",
        "# model = xgb.XGBRegressor()  # For regression tasks\n",
        "\n",
        "# Train the model\n",
        "xgbClassifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgbClassifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)  # For classification tasks\n",
        "# mse = mean_squared_error(y_test, y_pred)  # For regression tasks\n",
        "\n",
        "# Print the evaluation result\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EvT9DH0U1hf"
      },
      "outputs": [],
      "source": [
        "for i in range(5,15):\n",
        "  for a in ['auto', 'ball_tree', 'kd_tree', 'brute']:\n",
        "    knnClassifier = KNeighborsClassifier(n_neighbors=i, algorithm=a)\n",
        "    knnClassifier.fit(aX_train, ay_train)\n",
        "    y_pred = knnClassifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(a, \" with n :\", i, \" \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ufQOD6SwW3nQ",
        "outputId": "1bd07705-c74f-4ba1-d3f6-7399e31fc5c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f3125fbf-d627-4c95-a450-3cd3645319fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-2.033875</td>\n",
              "      <td>0.978446</td>\n",
              "      <td>-0.142131</td>\n",
              "      <td>-0.177117</td>\n",
              "      <td>-1.470684</td>\n",
              "      <td>1.669562</td>\n",
              "      <td>-0.196530</td>\n",
              "      <td>-0.125239</td>\n",
              "      <td>-0.452284</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.111266</td>\n",
              "      <td>0.716084</td>\n",
              "      <td>0.060039</td>\n",
              "      <td>0.301279</td>\n",
              "      <td>-1.174846</td>\n",
              "      <td>-1.076498</td>\n",
              "      <td>-0.069452</td>\n",
              "      <td>-0.604012</td>\n",
              "      <td>-2.179176</td>\n",
              "      <td>0.558003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.348835</td>\n",
              "      <td>0.294815</td>\n",
              "      <td>-0.557577</td>\n",
              "      <td>-2.020773</td>\n",
              "      <td>-1.234715</td>\n",
              "      <td>1.633930</td>\n",
              "      <td>-1.680658</td>\n",
              "      <td>-0.358146</td>\n",
              "      <td>0.166122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.735240</td>\n",
              "      <td>0.829781</td>\n",
              "      <td>1.521941</td>\n",
              "      <td>1.347946</td>\n",
              "      <td>0.754505</td>\n",
              "      <td>1.330642</td>\n",
              "      <td>-0.754453</td>\n",
              "      <td>0.582956</td>\n",
              "      <td>0.252671</td>\n",
              "      <td>1.495870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.113248</td>\n",
              "      <td>-0.607726</td>\n",
              "      <td>-0.947791</td>\n",
              "      <td>0.830851</td>\n",
              "      <td>0.998291</td>\n",
              "      <td>0.498321</td>\n",
              "      <td>-1.493958</td>\n",
              "      <td>0.789572</td>\n",
              "      <td>-1.311018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104698</td>\n",
              "      <td>0.616189</td>\n",
              "      <td>-1.035953</td>\n",
              "      <td>2.111387</td>\n",
              "      <td>-0.984415</td>\n",
              "      <td>1.148076</td>\n",
              "      <td>-1.433554</td>\n",
              "      <td>0.243372</td>\n",
              "      <td>0.170083</td>\n",
              "      <td>1.274795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1.223321</td>\n",
              "      <td>-0.479048</td>\n",
              "      <td>-1.925789</td>\n",
              "      <td>1.680377</td>\n",
              "      <td>0.021840</td>\n",
              "      <td>-1.453307</td>\n",
              "      <td>0.605559</td>\n",
              "      <td>-0.019024</td>\n",
              "      <td>1.065448</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360237</td>\n",
              "      <td>-1.957863</td>\n",
              "      <td>-0.123384</td>\n",
              "      <td>1.505329</td>\n",
              "      <td>0.660290</td>\n",
              "      <td>-1.769443</td>\n",
              "      <td>-0.547756</td>\n",
              "      <td>-0.568122</td>\n",
              "      <td>0.244645</td>\n",
              "      <td>0.982116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.160109</td>\n",
              "      <td>0.422684</td>\n",
              "      <td>-0.308029</td>\n",
              "      <td>0.227744</td>\n",
              "      <td>0.432854</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.193832</td>\n",
              "      <td>1.035091</td>\n",
              "      <td>-0.538868</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416629</td>\n",
              "      <td>1.441766</td>\n",
              "      <td>0.212572</td>\n",
              "      <td>-0.994721</td>\n",
              "      <td>1.143999</td>\n",
              "      <td>-2.166923</td>\n",
              "      <td>-1.199248</td>\n",
              "      <td>-1.028636</td>\n",
              "      <td>0.752791</td>\n",
              "      <td>0.317169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5245</th>\n",
              "      <td>0</td>\n",
              "      <td>1.157565</td>\n",
              "      <td>-0.142219</td>\n",
              "      <td>1.043992</td>\n",
              "      <td>1.144946</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>0.248978</td>\n",
              "      <td>-1.505100</td>\n",
              "      <td>-0.874137</td>\n",
              "      <td>-1.782724</td>\n",
              "      <td>...</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.255793</td>\n",
              "      <td>-0.154838</td>\n",
              "      <td>0.413029</td>\n",
              "      <td>-0.482939</td>\n",
              "      <td>-1.277953</td>\n",
              "      <td>-0.445082</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.924614</td>\n",
              "      <td>-0.432462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5246</th>\n",
              "      <td>0</td>\n",
              "      <td>1.424709</td>\n",
              "      <td>0.235910</td>\n",
              "      <td>1.356778</td>\n",
              "      <td>1.368099</td>\n",
              "      <td>-0.318862</td>\n",
              "      <td>1.039765</td>\n",
              "      <td>-0.986854</td>\n",
              "      <td>-0.330184</td>\n",
              "      <td>-1.383120</td>\n",
              "      <td>...</td>\n",
              "      <td>1.424709</td>\n",
              "      <td>-1.066107</td>\n",
              "      <td>0.881258</td>\n",
              "      <td>-0.488691</td>\n",
              "      <td>-1.281223</td>\n",
              "      <td>-1.213291</td>\n",
              "      <td>0.122692</td>\n",
              "      <td>1.175627</td>\n",
              "      <td>-1.145360</td>\n",
              "      <td>0.451026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5247</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.375687</td>\n",
              "      <td>1.524455</td>\n",
              "      <td>0.012514</td>\n",
              "      <td>-0.007917</td>\n",
              "      <td>0.073809</td>\n",
              "      <td>-0.906909</td>\n",
              "      <td>-1.254247</td>\n",
              "      <td>1.606182</td>\n",
              "      <td>0.298557</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028349</td>\n",
              "      <td>-0.968204</td>\n",
              "      <td>-1.233815</td>\n",
              "      <td>1.626613</td>\n",
              "      <td>-0.191802</td>\n",
              "      <td>1.115823</td>\n",
              "      <td>0.380284</td>\n",
              "      <td>-0.293960</td>\n",
              "      <td>0.135104</td>\n",
              "      <td>1.381434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5248</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.478238</td>\n",
              "      <td>1.666142</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-0.362771</td>\n",
              "      <td>1.798104</td>\n",
              "      <td>-0.214314</td>\n",
              "      <td>0.775400</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.428752</td>\n",
              "      <td>-1.121552</td>\n",
              "      <td>-0.379267</td>\n",
              "      <td>-0.593705</td>\n",
              "      <td>0.049609</td>\n",
              "      <td>1.765114</td>\n",
              "      <td>0.313533</td>\n",
              "      <td>-0.329781</td>\n",
              "      <td>-1.220524</td>\n",
              "      <td>0.033114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5249</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.750874</td>\n",
              "      <td>0.267008</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.179867</td>\n",
              "      <td>-0.155041</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.279173</td>\n",
              "      <td>1.731765</td>\n",
              "      <td>0.564925</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.303999</td>\n",
              "      <td>-0.850180</td>\n",
              "      <td>0.937321</td>\n",
              "      <td>-1.594972</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>1.582807</td>\n",
              "      <td>1.036626</td>\n",
              "      <td>-0.254346</td>\n",
              "      <td>0.664230</td>\n",
              "      <td>1.831071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10500 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3125fbf-d627-4c95-a450-3cd3645319fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3125fbf-d627-4c95-a450-3cd3645319fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3125fbf-d627-4c95-a450-3cd3645319fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      labels       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
              "0          0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562   \n",
              "1          1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
              "2          1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
              "3          0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
              "4          0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "5245       0  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978   \n",
              "5246       0  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765   \n",
              "5247       1 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909   \n",
              "5248       1 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104   \n",
              "5249       1 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999   \n",
              "\n",
              "           f_6       f_7       f_8  ...    f_1190    f_1191    f_1192  \\\n",
              "0    -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039   \n",
              "1    -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941   \n",
              "2    -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953   \n",
              "3     0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384   \n",
              "4     0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5245 -1.505100 -0.874137 -1.782724  ...  1.195423 -0.255793 -0.154838   \n",
              "5246 -0.986854 -0.330184 -1.383120  ...  1.424709 -1.066107  0.881258   \n",
              "5247 -1.254247  1.606182  0.298557  ... -0.028349 -0.968204 -1.233815   \n",
              "5248 -0.214314  0.775400 -0.379267  ... -0.428752 -1.121552 -0.379267   \n",
              "5249 -0.279173  1.731765  0.564925  ... -0.303999 -0.850180  0.937321   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0     0.301279 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
              "1     1.347946  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
              "2     2.111387 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
              "3     1.505329  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
              "4    -0.994721  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "5245  0.413029 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462  \n",
              "5246 -0.488691 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026  \n",
              "5247  1.626613 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434  \n",
              "5248 -0.593705  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114  \n",
              "5249 -1.594972  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071  \n",
              "\n",
              "[10500 rows x 1201 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aug_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "7KCpM2dCVirT",
        "outputId": "2ad07836-645f-4f65-bb7b-b7d91b00bad9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knnClassifier = KNeighborsClassifier(n_neighbors=5, algorithm='auto')\n",
        "knnClassifier.fit(aX_train, ay_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "8FqdbJS6Y1Z9",
        "outputId": "457d94a1-12ae-4aa7-feba-c44b5e337435"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4bab24f9-b2c8-4dec-8458-d6121deabc29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_10</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1181</th>\n",
              "      <th>f_1182</th>\n",
              "      <th>f_1185</th>\n",
              "      <th>f_1186</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>-1.485896</td>\n",
              "      <td>...</td>\n",
              "      <td>0.752675</td>\n",
              "      <td>-1.077703</td>\n",
              "      <td>1.431924</td>\n",
              "      <td>-0.013587</td>\n",
              "      <td>-0.776403</td>\n",
              "      <td>-0.662884</td>\n",
              "      <td>-0.257091</td>\n",
              "      <td>-1.168413</td>\n",
              "      <td>-0.482520</td>\n",
              "      <td>-0.085453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>-0.099658</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>0.505176</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.298254</td>\n",
              "      <td>0.100701</td>\n",
              "      <td>0.605404</td>\n",
              "      <td>0.065069</td>\n",
              "      <td>0.379635</td>\n",
              "      <td>-1.760084</td>\n",
              "      <td>1.125450</td>\n",
              "      <td>-0.328047</td>\n",
              "      <td>-1.257607</td>\n",
              "      <td>0.964312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>0.224159</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.403457</td>\n",
              "      <td>-2.438368</td>\n",
              "      <td>0.089148</td>\n",
              "      <td>-0.205051</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.373589</td>\n",
              "      <td>-0.483701</td>\n",
              "      <td>-0.964782</td>\n",
              "      <td>0.066040</td>\n",
              "      <td>-0.444567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>1.226839</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>-0.391189</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137612</td>\n",
              "      <td>0.362197</td>\n",
              "      <td>-0.637794</td>\n",
              "      <td>0.524736</td>\n",
              "      <td>-0.442288</td>\n",
              "      <td>-2.794472</td>\n",
              "      <td>-0.763468</td>\n",
              "      <td>-0.789832</td>\n",
              "      <td>-2.703150</td>\n",
              "      <td>-2.058728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>0.518777</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>-0.019973</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.904386</td>\n",
              "      <td>-0.383635</td>\n",
              "      <td>-1.709187</td>\n",
              "      <td>-0.296326</td>\n",
              "      <td>-2.624450</td>\n",
              "      <td>-3.200223</td>\n",
              "      <td>0.711422</td>\n",
              "      <td>-0.190394</td>\n",
              "      <td>-1.656639</td>\n",
              "      <td>0.707360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>2246</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.319077</td>\n",
              "      <td>0.849589</td>\n",
              "      <td>0.822723</td>\n",
              "      <td>0.325704</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.910127</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.574303</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.493706</td>\n",
              "      <td>0.836156</td>\n",
              "      <td>-1.272816</td>\n",
              "      <td>0.016746</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-2.226556</td>\n",
              "      <td>-0.090717</td>\n",
              "      <td>-1.393713</td>\n",
              "      <td>-0.399675</td>\n",
              "      <td>-0.856395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>2247</td>\n",
              "      <td>1.005737</td>\n",
              "      <td>-0.064755</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>0.724028</td>\n",
              "      <td>0.712760</td>\n",
              "      <td>-0.785929</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>-1.101443</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.729587</td>\n",
              "      <td>1.129689</td>\n",
              "      <td>-1.619786</td>\n",
              "      <td>0.757833</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.270468</td>\n",
              "      <td>-0.932417</td>\n",
              "      <td>-1.169053</td>\n",
              "      <td>-0.605636</td>\n",
              "      <td>-0.323927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>2248</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>1.223561</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.987156</td>\n",
              "      <td>-0.003031</td>\n",
              "      <td>-1.158309</td>\n",
              "      <td>1.237823</td>\n",
              "      <td>-1.272410</td>\n",
              "      <td>-1.029945</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.031556</td>\n",
              "      <td>-1.429300</td>\n",
              "      <td>-0.245497</td>\n",
              "      <td>1.009620</td>\n",
              "      <td>0.581740</td>\n",
              "      <td>-1.386512</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>-1.243885</td>\n",
              "      <td>-0.630589</td>\n",
              "      <td>1.594391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>2249</td>\n",
              "      <td>1.042624</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.066538</td>\n",
              "      <td>1.030667</td>\n",
              "      <td>0.707827</td>\n",
              "      <td>-1.396612</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-1.025944</td>\n",
              "      <td>-0.224822</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.205300</td>\n",
              "      <td>0.970882</td>\n",
              "      <td>-0.404178</td>\n",
              "      <td>0.588257</td>\n",
              "      <td>1.078495</td>\n",
              "      <td>-1.193343</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>-0.081338</td>\n",
              "      <td>-0.368307</td>\n",
              "      <td>-0.129166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>2250</td>\n",
              "      <td>-1.319572</td>\n",
              "      <td>-0.485173</td>\n",
              "      <td>-0.098500</td>\n",
              "      <td>2.323293</td>\n",
              "      <td>-0.953250</td>\n",
              "      <td>0.084661</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>1.427840</td>\n",
              "      <td>0.450983</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.011513</td>\n",
              "      <td>0.003256</td>\n",
              "      <td>-0.688685</td>\n",
              "      <td>-0.179905</td>\n",
              "      <td>-0.505524</td>\n",
              "      <td>-0.220607</td>\n",
              "      <td>-0.871845</td>\n",
              "      <td>0.654495</td>\n",
              "      <td>-0.444470</td>\n",
              "      <td>-0.118851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 717 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bab24f9-b2c8-4dec-8458-d6121deabc29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bab24f9-b2c8-4dec-8458-d6121deabc29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bab24f9-b2c8-4dec-8458-d6121deabc29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id       f_0       f_1       f_2       f_3       f_5       f_6  \\\n",
              "0        1 -3.388242  0.868285 -0.427619 -0.678964  0.262761  1.243040   \n",
              "1        2 -0.496920  0.952381  0.989040  0.451422 -0.099658 -1.124326   \n",
              "2        3  1.128369 -0.537951  2.544358  1.165254  0.776961 -0.495768   \n",
              "3        4  0.051253  1.746814  0.681177  1.844524  1.226839 -0.085519   \n",
              "4        5  1.423209 -0.983594 -1.694170  1.197507  0.518777 -0.298612   \n",
              "...    ...       ...       ...       ...       ...       ...       ...   \n",
              "2245  2246  0.889888 -0.319077  0.849589  0.822723  0.325704  0.876455   \n",
              "2246  2247  1.005737 -0.064755  1.163494  1.163494  0.724028  0.712760   \n",
              "2247  2248  1.252086  1.223561  0.153859 -0.987156 -0.003031 -1.158309   \n",
              "2248  2249  1.042624 -0.129166  1.066538  1.030667  0.707827 -1.396612   \n",
              "2249  2250 -1.319572 -0.485173 -0.098500  2.323293 -0.953250  0.084661   \n",
              "\n",
              "           f_7       f_8      f_10  ...    f_1181    f_1182    f_1185  \\\n",
              "0     1.537751 -0.352028 -1.485896  ...  0.752675 -1.077703  1.431924   \n",
              "1     0.729430 -0.216224  0.505176  ... -1.298254  0.100701  0.605404   \n",
              "2     0.060111 -1.418468  0.224159  ... -1.403457 -2.438368  0.089148   \n",
              "3     0.379008 -1.003667 -0.391189  ...  0.137612  0.362197 -0.637794   \n",
              "4    -0.365174  0.738447 -0.019973  ... -0.904386 -0.383635 -1.709187   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2245 -0.910127  0.889888 -0.574303  ... -0.493706  0.836156 -1.272816   \n",
              "2246 -0.785929 -1.225394 -1.101443  ... -0.729587  1.129689 -1.619786   \n",
              "2247  1.237823 -1.272410 -1.029945  ... -0.031556 -1.429300 -0.245497   \n",
              "2248  0.014319 -1.025944 -0.224822  ... -1.205300  0.970882 -0.404178   \n",
              "2249 -0.566577  1.427840  0.450983  ... -2.011513  0.003256 -0.688685   \n",
              "\n",
              "        f_1186    f_1190    f_1191    f_1192    f_1193    f_1195    f_1196  \n",
              "0    -0.013587 -0.776403 -0.662884 -0.257091 -1.168413 -0.482520 -0.085453  \n",
              "1     0.065069  0.379635 -1.760084  1.125450 -0.328047 -1.257607  0.964312  \n",
              "2    -0.205051  1.165254 -1.373589 -0.483701 -0.964782  0.066040 -0.444567  \n",
              "3     0.524736 -0.442288 -2.794472 -0.763468 -0.789832 -2.703150 -2.058728  \n",
              "4    -0.296326 -2.624450 -3.200223  0.711422 -0.190394 -1.656639  0.707360  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2245  0.016746  0.889888 -2.226556 -0.090717 -1.393713 -0.399675 -0.856395  \n",
              "2246  0.757833  1.163494 -1.270468 -0.932417 -1.169053 -0.605636 -0.323927  \n",
              "2247  1.009620  0.581740 -1.386512  0.809943 -1.243885 -0.630589  1.594391  \n",
              "2248  0.588257  1.078495 -1.193343  0.086061 -0.081338 -0.368307 -0.129166  \n",
              "2249 -0.179905 -0.505524 -0.220607 -0.871845  0.654495 -0.444470 -0.118851  \n",
              "\n",
              "[2250 rows x 717 columns]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D53TBh0vXDpR"
      },
      "outputs": [],
      "source": [
        "sub = testdf.iloc[:, 1:]\n",
        "sub = sub.iloc[:, importantfeatures]\n",
        "testdf['labels'] = knnClassifier.predict(sub)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEGrWJs9Xa1l"
      },
      "outputs": [],
      "source": [
        "submission = testdf[['id', 'labels']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5ZEycpqXdWc"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('5n_knn_waugs_importance0.1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpsZS2cl2Eln",
        "outputId": "02f0ac98-1df9-43c6-aa0c-7d9e6ffef930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7704761904761904\n",
            "0.8466666666666667\n",
            "0.8476190476190476\n",
            "0.8466666666666667\n"
          ]
        }
      ],
      "source": [
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "for k in kernels:\n",
        "  SVClassifier = SVC(kernel=k)\n",
        "  SVClassifier.fit(X_train, y_train)\n",
        "  y_pred = SVClassifier.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb2N5fsa4lc6",
        "outputId": "a1273ae0-8885-4ba9-e19a-1caddcc9b5aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7647619047619048\n",
            "0.758095238095238\n",
            "0.7647619047619048\n"
          ]
        }
      ],
      "source": [
        "crit = ['gini', 'entropy', 'log_loss']\n",
        "for c in crit:\n",
        "  dtclass = DecisionTreeClassifier(criterion=c)\n",
        "  dtclass.fit(X_train, y_train)\n",
        "  y_pred = dtclass.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(c, \" \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "j_IJRMnRvc8z",
        "outputId": "d602e4c1-5031-432b-a04a-5e4bc1e91a95"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-069fb457e7f6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# split the dataset into train and test datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# define the base models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlevel0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2559\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5250, 10500]"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# split the dataset into train and test datasets\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# define the base models\n",
        "level0 = list()\n",
        "# level0.append(('lr', LogisticRegression()))\n",
        "level0.append(('knn', KNeighborsClassifier(n_neighbors =8)))\n",
        "# level0.append(('cart', DecisionTreeClassifier()))\n",
        "level0.append(('svm', SVC()))\n",
        "level0.append(('xgb', xgb.XGBClassifier()))\n",
        "\n",
        "# define meta learner model\n",
        "level1 = RandomForestClassifier()\n",
        "\n",
        "# define the stacking ensemble\n",
        "ensemble = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "\n",
        "# fit the model on all available data\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# make a prediction for one instance\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "# evaluate the model\n",
        "print('Accuracy: ', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ABmNHfswu1v"
      },
      "outputs": [],
      "source": [
        "testdf\n",
        "testdata = testdf.iloc[:, 1:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "unSHHv5Ex5j0",
        "outputId": "4d7c5418-be87-4331-c1a2-81e7b2e66198"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-784f553e-14ac-42b4-9595-36b81082a5a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>-1.625735</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>-0.114245</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.776403</td>\n",
              "      <td>-0.662884</td>\n",
              "      <td>-0.257091</td>\n",
              "      <td>-1.168413</td>\n",
              "      <td>0.223260</td>\n",
              "      <td>-0.482520</td>\n",
              "      <td>-0.085453</td>\n",
              "      <td>-0.382265</td>\n",
              "      <td>-0.539349</td>\n",
              "      <td>-1.682404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>0.513516</td>\n",
              "      <td>-0.099658</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>-0.000680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.379635</td>\n",
              "      <td>-1.760084</td>\n",
              "      <td>1.125450</td>\n",
              "      <td>-0.328047</td>\n",
              "      <td>-0.880305</td>\n",
              "      <td>-1.257607</td>\n",
              "      <td>0.964312</td>\n",
              "      <td>2.021104</td>\n",
              "      <td>0.655021</td>\n",
              "      <td>-0.423029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.904994</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>-0.086128</td>\n",
              "      <td>...</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.373589</td>\n",
              "      <td>-0.483701</td>\n",
              "      <td>-0.964782</td>\n",
              "      <td>-0.869555</td>\n",
              "      <td>0.066040</td>\n",
              "      <td>-0.444567</td>\n",
              "      <td>-0.531935</td>\n",
              "      <td>-0.878660</td>\n",
              "      <td>1.099488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>-0.327977</td>\n",
              "      <td>1.226839</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>0.570237</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.442288</td>\n",
              "      <td>-2.794472</td>\n",
              "      <td>-0.763468</td>\n",
              "      <td>-0.789832</td>\n",
              "      <td>-0.113209</td>\n",
              "      <td>-2.703150</td>\n",
              "      <td>-2.058728</td>\n",
              "      <td>1.070627</td>\n",
              "      <td>-0.458045</td>\n",
              "      <td>-0.435825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>1.044211</td>\n",
              "      <td>0.518777</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>0.054435</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.624450</td>\n",
              "      <td>-3.200223</td>\n",
              "      <td>0.711422</td>\n",
              "      <td>-0.190394</td>\n",
              "      <td>0.337224</td>\n",
              "      <td>-1.656639</td>\n",
              "      <td>0.707360</td>\n",
              "      <td>-0.562290</td>\n",
              "      <td>1.471181</td>\n",
              "      <td>-0.192000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.319077</td>\n",
              "      <td>0.849589</td>\n",
              "      <td>0.822723</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.325704</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.910127</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>0.204808</td>\n",
              "      <td>...</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-2.226556</td>\n",
              "      <td>-0.090717</td>\n",
              "      <td>-1.393713</td>\n",
              "      <td>-0.896694</td>\n",
              "      <td>-0.399675</td>\n",
              "      <td>-0.856395</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.863022</td>\n",
              "      <td>-0.601169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>1.005737</td>\n",
              "      <td>-0.064755</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>0.724028</td>\n",
              "      <td>0.712760</td>\n",
              "      <td>-0.785929</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>1.107152</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.270468</td>\n",
              "      <td>-0.932417</td>\n",
              "      <td>-1.169053</td>\n",
              "      <td>-0.008414</td>\n",
              "      <td>-0.605636</td>\n",
              "      <td>-0.323927</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.315541</td>\n",
              "      <td>0.047928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>1.252086</td>\n",
              "      <td>1.223561</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.987156</td>\n",
              "      <td>0.239435</td>\n",
              "      <td>-0.003031</td>\n",
              "      <td>-1.158309</td>\n",
              "      <td>1.237823</td>\n",
              "      <td>-1.272410</td>\n",
              "      <td>0.767154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.581740</td>\n",
              "      <td>-1.386512</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>-1.243885</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.630589</td>\n",
              "      <td>1.594391</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>-1.429300</td>\n",
              "      <td>1.408976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>1.042624</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.066538</td>\n",
              "      <td>1.030667</td>\n",
              "      <td>1.162195</td>\n",
              "      <td>0.707827</td>\n",
              "      <td>-1.396612</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-1.025944</td>\n",
              "      <td>0.982839</td>\n",
              "      <td>...</td>\n",
              "      <td>1.078495</td>\n",
              "      <td>-1.193343</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>-0.081338</td>\n",
              "      <td>-0.978116</td>\n",
              "      <td>-0.368307</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.090452</td>\n",
              "      <td>-1.444440</td>\n",
              "      <td>0.468686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>-1.319572</td>\n",
              "      <td>-0.485173</td>\n",
              "      <td>-0.098500</td>\n",
              "      <td>2.323293</td>\n",
              "      <td>-0.139202</td>\n",
              "      <td>-0.953250</td>\n",
              "      <td>0.084661</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>1.427840</td>\n",
              "      <td>-0.403768</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.505524</td>\n",
              "      <td>-0.220607</td>\n",
              "      <td>-0.871845</td>\n",
              "      <td>0.654495</td>\n",
              "      <td>0.430631</td>\n",
              "      <td>-0.444470</td>\n",
              "      <td>-0.118851</td>\n",
              "      <td>0.471334</td>\n",
              "      <td>-0.078149</td>\n",
              "      <td>-0.566577</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-784f553e-14ac-42b4-9595-36b81082a5a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-784f553e-14ac-42b4-9595-36b81082a5a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-784f553e-14ac-42b4-9595-36b81082a5a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "0    -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  1.243040   \n",
              "1    -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658 -1.124326   \n",
              "2     1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961 -0.495768   \n",
              "3     0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839 -0.085519   \n",
              "4     1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777 -0.298612   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2245  0.889888 -0.319077  0.849589  0.822723  0.876455  0.325704  0.876455   \n",
              "2246  1.005737 -0.064755  1.163494  1.163494  1.163494  0.724028  0.712760   \n",
              "2247  1.252086  1.223561  0.153859 -0.987156  0.239435 -0.003031 -1.158309   \n",
              "2248  1.042624 -0.129166  1.066538  1.030667  1.162195  0.707827 -1.396612   \n",
              "2249 -1.319572 -0.485173 -0.098500  2.323293 -0.139202 -0.953250  0.084661   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "0     1.537751 -0.352028 -0.114245  ... -0.776403 -0.662884 -0.257091   \n",
              "1     0.729430 -0.216224 -0.000680  ...  0.379635 -1.760084  1.125450   \n",
              "2     0.060111 -1.418468 -0.086128  ...  1.165254 -1.373589 -0.483701   \n",
              "3     0.379008 -1.003667  0.570237  ... -0.442288 -2.794472 -0.763468   \n",
              "4    -0.365174  0.738447  0.054435  ... -2.624450 -3.200223  0.711422   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2245 -0.910127  0.889888  0.204808  ...  0.889888 -2.226556 -0.090717   \n",
              "2246 -0.785929 -1.225394  1.107152  ...  1.163494 -1.270468 -0.932417   \n",
              "2247  1.237823 -1.272410  0.767154  ...  0.581740 -1.386512  0.809943   \n",
              "2248  0.014319 -1.025944  0.982839  ...  1.078495 -1.193343  0.086061   \n",
              "2249 -0.566577  1.427840 -0.403768  ... -0.505524 -0.220607 -0.871845   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0    -1.168413  0.223260 -0.482520 -0.085453 -0.382265 -0.539349 -1.682404  \n",
              "1    -0.328047 -0.880305 -1.257607  0.964312  2.021104  0.655021 -0.423029  \n",
              "2    -0.964782 -0.869555  0.066040 -0.444567 -0.531935 -0.878660  1.099488  \n",
              "3    -0.789832 -0.113209 -2.703150 -2.058728  1.070627 -0.458045 -0.435825  \n",
              "4    -0.190394  0.337224 -1.656639  0.707360 -0.562290  1.471181 -0.192000  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2245 -1.393713 -0.896694 -0.399675 -0.856395  0.876455  0.863022 -0.601169  \n",
              "2246 -1.169053 -0.008414 -0.605636 -0.323927  1.163494 -1.315541  0.047928  \n",
              "2247 -1.243885  0.153859 -0.630589  1.594391  1.252086 -1.429300  1.408976  \n",
              "2248 -0.081338 -0.978116 -0.368307 -0.129166  1.090452 -1.444440  0.468686  \n",
              "2249  0.654495  0.430631 -0.444470 -0.118851  0.471334 -0.078149 -0.566577  \n",
              "\n",
              "[2250 rows x 1200 columns]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "0VU_RIw48Nh-",
        "outputId": "3d9097a3-f542-4b2e-dcd9-7a86f8eeb62c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-34b94654-5f02-48c3-aa25-8125ab8c345a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1190</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>-1.625735</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>-0.114245</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.776403</td>\n",
              "      <td>-0.662884</td>\n",
              "      <td>-0.257091</td>\n",
              "      <td>-1.168413</td>\n",
              "      <td>0.223260</td>\n",
              "      <td>-0.482520</td>\n",
              "      <td>-0.085453</td>\n",
              "      <td>-0.382265</td>\n",
              "      <td>-0.539349</td>\n",
              "      <td>-1.682404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>0.513516</td>\n",
              "      <td>-0.099658</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>-0.000680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.379635</td>\n",
              "      <td>-1.760084</td>\n",
              "      <td>1.125450</td>\n",
              "      <td>-0.328047</td>\n",
              "      <td>-0.880305</td>\n",
              "      <td>-1.257607</td>\n",
              "      <td>0.964312</td>\n",
              "      <td>2.021104</td>\n",
              "      <td>0.655021</td>\n",
              "      <td>-0.423029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.904994</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>-0.086128</td>\n",
              "      <td>...</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.373589</td>\n",
              "      <td>-0.483701</td>\n",
              "      <td>-0.964782</td>\n",
              "      <td>-0.869555</td>\n",
              "      <td>0.066040</td>\n",
              "      <td>-0.444567</td>\n",
              "      <td>-0.531935</td>\n",
              "      <td>-0.878660</td>\n",
              "      <td>1.099488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>-0.327977</td>\n",
              "      <td>1.226839</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>0.570237</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.442288</td>\n",
              "      <td>-2.794472</td>\n",
              "      <td>-0.763468</td>\n",
              "      <td>-0.789832</td>\n",
              "      <td>-0.113209</td>\n",
              "      <td>-2.703150</td>\n",
              "      <td>-2.058728</td>\n",
              "      <td>1.070627</td>\n",
              "      <td>-0.458045</td>\n",
              "      <td>-0.435825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>1.044211</td>\n",
              "      <td>0.518777</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>0.054435</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.624450</td>\n",
              "      <td>-3.200223</td>\n",
              "      <td>0.711422</td>\n",
              "      <td>-0.190394</td>\n",
              "      <td>0.337224</td>\n",
              "      <td>-1.656639</td>\n",
              "      <td>0.707360</td>\n",
              "      <td>-0.562290</td>\n",
              "      <td>1.471181</td>\n",
              "      <td>-0.192000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.319077</td>\n",
              "      <td>0.849589</td>\n",
              "      <td>0.822723</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.325704</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.910127</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>0.204808</td>\n",
              "      <td>...</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-2.226556</td>\n",
              "      <td>-0.090717</td>\n",
              "      <td>-1.393713</td>\n",
              "      <td>-0.896694</td>\n",
              "      <td>-0.399675</td>\n",
              "      <td>-0.856395</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.863022</td>\n",
              "      <td>-0.601169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>1.005737</td>\n",
              "      <td>-0.064755</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>0.724028</td>\n",
              "      <td>0.712760</td>\n",
              "      <td>-0.785929</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>1.107152</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.270468</td>\n",
              "      <td>-0.932417</td>\n",
              "      <td>-1.169053</td>\n",
              "      <td>-0.008414</td>\n",
              "      <td>-0.605636</td>\n",
              "      <td>-0.323927</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.315541</td>\n",
              "      <td>0.047928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>1.252086</td>\n",
              "      <td>1.223561</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.987156</td>\n",
              "      <td>0.239435</td>\n",
              "      <td>-0.003031</td>\n",
              "      <td>-1.158309</td>\n",
              "      <td>1.237823</td>\n",
              "      <td>-1.272410</td>\n",
              "      <td>0.767154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.581740</td>\n",
              "      <td>-1.386512</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>-1.243885</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.630589</td>\n",
              "      <td>1.594391</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>-1.429300</td>\n",
              "      <td>1.408976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>1.042624</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.066538</td>\n",
              "      <td>1.030667</td>\n",
              "      <td>1.162195</td>\n",
              "      <td>0.707827</td>\n",
              "      <td>-1.396612</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-1.025944</td>\n",
              "      <td>0.982839</td>\n",
              "      <td>...</td>\n",
              "      <td>1.078495</td>\n",
              "      <td>-1.193343</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>-0.081338</td>\n",
              "      <td>-0.978116</td>\n",
              "      <td>-0.368307</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.090452</td>\n",
              "      <td>-1.444440</td>\n",
              "      <td>0.468686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>-1.319572</td>\n",
              "      <td>-0.485173</td>\n",
              "      <td>-0.098500</td>\n",
              "      <td>2.323293</td>\n",
              "      <td>-0.139202</td>\n",
              "      <td>-0.953250</td>\n",
              "      <td>0.084661</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>1.427840</td>\n",
              "      <td>-0.403768</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.505524</td>\n",
              "      <td>-0.220607</td>\n",
              "      <td>-0.871845</td>\n",
              "      <td>0.654495</td>\n",
              "      <td>0.430631</td>\n",
              "      <td>-0.444470</td>\n",
              "      <td>-0.118851</td>\n",
              "      <td>0.471334</td>\n",
              "      <td>-0.078149</td>\n",
              "      <td>-0.566577</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 1200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34b94654-5f02-48c3-aa25-8125ab8c345a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34b94654-5f02-48c3-aa25-8125ab8c345a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34b94654-5f02-48c3-aa25-8125ab8c345a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "0    -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  1.243040   \n",
              "1    -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658 -1.124326   \n",
              "2     1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961 -0.495768   \n",
              "3     0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839 -0.085519   \n",
              "4     1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777 -0.298612   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2245  0.889888 -0.319077  0.849589  0.822723  0.876455  0.325704  0.876455   \n",
              "2246  1.005737 -0.064755  1.163494  1.163494  1.163494  0.724028  0.712760   \n",
              "2247  1.252086  1.223561  0.153859 -0.987156  0.239435 -0.003031 -1.158309   \n",
              "2248  1.042624 -0.129166  1.066538  1.030667  1.162195  0.707827 -1.396612   \n",
              "2249 -1.319572 -0.485173 -0.098500  2.323293 -0.139202 -0.953250  0.084661   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1190    f_1191    f_1192  \\\n",
              "0     1.537751 -0.352028 -0.114245  ... -0.776403 -0.662884 -0.257091   \n",
              "1     0.729430 -0.216224 -0.000680  ...  0.379635 -1.760084  1.125450   \n",
              "2     0.060111 -1.418468 -0.086128  ...  1.165254 -1.373589 -0.483701   \n",
              "3     0.379008 -1.003667  0.570237  ... -0.442288 -2.794472 -0.763468   \n",
              "4    -0.365174  0.738447  0.054435  ... -2.624450 -3.200223  0.711422   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2245 -0.910127  0.889888  0.204808  ...  0.889888 -2.226556 -0.090717   \n",
              "2246 -0.785929 -1.225394  1.107152  ...  1.163494 -1.270468 -0.932417   \n",
              "2247  1.237823 -1.272410  0.767154  ...  0.581740 -1.386512  0.809943   \n",
              "2248  0.014319 -1.025944  0.982839  ...  1.078495 -1.193343  0.086061   \n",
              "2249 -0.566577  1.427840 -0.403768  ... -0.505524 -0.220607 -0.871845   \n",
              "\n",
              "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
              "0    -1.168413  0.223260 -0.482520 -0.085453 -0.382265 -0.539349 -1.682404  \n",
              "1    -0.328047 -0.880305 -1.257607  0.964312  2.021104  0.655021 -0.423029  \n",
              "2    -0.964782 -0.869555  0.066040 -0.444567 -0.531935 -0.878660  1.099488  \n",
              "3    -0.789832 -0.113209 -2.703150 -2.058728  1.070627 -0.458045 -0.435825  \n",
              "4    -0.190394  0.337224 -1.656639  0.707360 -0.562290  1.471181 -0.192000  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2245 -1.393713 -0.896694 -0.399675 -0.856395  0.876455  0.863022 -0.601169  \n",
              "2246 -1.169053 -0.008414 -0.605636 -0.323927  1.163494 -1.315541  0.047928  \n",
              "2247 -1.243885  0.153859 -0.630589  1.594391  1.252086 -1.429300  1.408976  \n",
              "2248 -0.081338 -0.978116 -0.368307 -0.129166  1.090452 -1.444440  0.468686  \n",
              "2249  0.654495  0.430631 -0.444470 -0.118851  0.471334 -0.078149 -0.566577  \n",
              "\n",
              "[2250 rows x 1200 columns]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "lK6U-95x7tco",
        "outputId": "bfa08408-ce3f-41e3-d30b-270a3d65cf8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=8)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=8)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knnClassifier = KNeighborsClassifier(n_neighbors=8)\n",
        "knnClassifier.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "1sZqRdtK8nlU",
        "outputId": "98371508-ff0c-4a78-be35-8c5350f91ef5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e81d4960a447>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mknnClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-e81d4960a447>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mknnClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'knnClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "testdata['classification'] = testdata.apply(lambda x: knnClassifier.predict(np.array(x).reshape(1,-1))[0],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "MWNJsWlbxz-f",
        "outputId": "c0fb7495-8fdf-44bc-f09a-02ada4f9ace3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3eed8c57-7588-42b0-b20e-8af267a91793\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>-1.625735</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>-0.114245</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.662884</td>\n",
              "      <td>-0.257091</td>\n",
              "      <td>-1.168413</td>\n",
              "      <td>0.223260</td>\n",
              "      <td>-0.482520</td>\n",
              "      <td>-0.085453</td>\n",
              "      <td>-0.382265</td>\n",
              "      <td>-0.539349</td>\n",
              "      <td>-1.682404</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>0.513516</td>\n",
              "      <td>-0.099658</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>-0.000680</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.760084</td>\n",
              "      <td>1.125450</td>\n",
              "      <td>-0.328047</td>\n",
              "      <td>-0.880305</td>\n",
              "      <td>-1.257607</td>\n",
              "      <td>0.964312</td>\n",
              "      <td>2.021104</td>\n",
              "      <td>0.655021</td>\n",
              "      <td>-0.423029</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.904994</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>-0.086128</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.373589</td>\n",
              "      <td>-0.483701</td>\n",
              "      <td>-0.964782</td>\n",
              "      <td>-0.869555</td>\n",
              "      <td>0.066040</td>\n",
              "      <td>-0.444567</td>\n",
              "      <td>-0.531935</td>\n",
              "      <td>-0.878660</td>\n",
              "      <td>1.099488</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>-0.327977</td>\n",
              "      <td>1.226839</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>0.570237</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.794472</td>\n",
              "      <td>-0.763468</td>\n",
              "      <td>-0.789832</td>\n",
              "      <td>-0.113209</td>\n",
              "      <td>-2.703150</td>\n",
              "      <td>-2.058728</td>\n",
              "      <td>1.070627</td>\n",
              "      <td>-0.458045</td>\n",
              "      <td>-0.435825</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>1.044211</td>\n",
              "      <td>0.518777</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>0.054435</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.200223</td>\n",
              "      <td>0.711422</td>\n",
              "      <td>-0.190394</td>\n",
              "      <td>0.337224</td>\n",
              "      <td>-1.656639</td>\n",
              "      <td>0.707360</td>\n",
              "      <td>-0.562290</td>\n",
              "      <td>1.471181</td>\n",
              "      <td>-0.192000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>0.812448</td>\n",
              "      <td>-0.887585</td>\n",
              "      <td>-1.720241</td>\n",
              "      <td>0.037756</td>\n",
              "      <td>-0.027353</td>\n",
              "      <td>0.455336</td>\n",
              "      <td>-0.147746</td>\n",
              "      <td>0.374871</td>\n",
              "      <td>0.806206</td>\n",
              "      <td>0.469159</td>\n",
              "      <td>...</td>\n",
              "      <td>2.087044</td>\n",
              "      <td>-0.281406</td>\n",
              "      <td>0.854356</td>\n",
              "      <td>0.350275</td>\n",
              "      <td>-0.784948</td>\n",
              "      <td>-2.347357</td>\n",
              "      <td>-1.066917</td>\n",
              "      <td>1.159733</td>\n",
              "      <td>-1.065897</td>\n",
              "      <td>798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>-0.230829</td>\n",
              "      <td>1.587434</td>\n",
              "      <td>-0.071908</td>\n",
              "      <td>-0.364252</td>\n",
              "      <td>-0.875762</td>\n",
              "      <td>-1.123044</td>\n",
              "      <td>-0.356475</td>\n",
              "      <td>-0.889185</td>\n",
              "      <td>-0.547437</td>\n",
              "      <td>-2.716407</td>\n",
              "      <td>...</td>\n",
              "      <td>0.270115</td>\n",
              "      <td>-0.536932</td>\n",
              "      <td>0.556702</td>\n",
              "      <td>-1.732274</td>\n",
              "      <td>0.839805</td>\n",
              "      <td>1.518645</td>\n",
              "      <td>0.303668</td>\n",
              "      <td>0.924748</td>\n",
              "      <td>0.250863</td>\n",
              "      <td>799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>3.175862</td>\n",
              "      <td>0.427759</td>\n",
              "      <td>1.490084</td>\n",
              "      <td>1.494840</td>\n",
              "      <td>-0.162264</td>\n",
              "      <td>0.995142</td>\n",
              "      <td>-1.482904</td>\n",
              "      <td>0.105556</td>\n",
              "      <td>2.473965</td>\n",
              "      <td>2.102029</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.902026</td>\n",
              "      <td>0.370415</td>\n",
              "      <td>-1.169859</td>\n",
              "      <td>0.381954</td>\n",
              "      <td>1.242291</td>\n",
              "      <td>-0.889109</td>\n",
              "      <td>0.788108</td>\n",
              "      <td>0.474568</td>\n",
              "      <td>0.628787</td>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>0.704484</td>\n",
              "      <td>-1.842615</td>\n",
              "      <td>0.675625</td>\n",
              "      <td>-0.275646</td>\n",
              "      <td>0.552615</td>\n",
              "      <td>1.390984</td>\n",
              "      <td>-1.252065</td>\n",
              "      <td>0.998914</td>\n",
              "      <td>1.702821</td>\n",
              "      <td>0.090807</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.554158</td>\n",
              "      <td>-0.502601</td>\n",
              "      <td>0.142170</td>\n",
              "      <td>1.494715</td>\n",
              "      <td>0.560818</td>\n",
              "      <td>2.047255</td>\n",
              "      <td>-0.344430</td>\n",
              "      <td>-0.925758</td>\n",
              "      <td>2.174152</td>\n",
              "      <td>801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>1.228876</td>\n",
              "      <td>1.406379</td>\n",
              "      <td>1.705329</td>\n",
              "      <td>1.828846</td>\n",
              "      <td>-1.456017</td>\n",
              "      <td>0.836773</td>\n",
              "      <td>-0.079571</td>\n",
              "      <td>0.558133</td>\n",
              "      <td>1.482729</td>\n",
              "      <td>1.065893</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802 rows × 1201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3eed8c57-7588-42b0-b20e-8af267a91793')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3eed8c57-7588-42b0-b20e-8af267a91793 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3eed8c57-7588-42b0-b20e-8af267a91793');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "0   -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  1.243040   \n",
              "1   -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658 -1.124326   \n",
              "2    1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961 -0.495768   \n",
              "3    0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839 -0.085519   \n",
              "4    1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777 -0.298612   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "797  0.812448 -0.887585 -1.720241  0.037756 -0.027353  0.455336 -0.147746   \n",
              "798 -0.230829  1.587434 -0.071908 -0.364252 -0.875762 -1.123044 -0.356475   \n",
              "799  3.175862  0.427759  1.490084  1.494840 -0.162264  0.995142 -1.482904   \n",
              "800  0.704484 -1.842615  0.675625 -0.275646  0.552615  1.390984 -1.252065   \n",
              "801  1.228876  1.406379  1.705329  1.828846 -1.456017  0.836773 -0.079571   \n",
              "\n",
              "          f_7       f_8       f_9  ...    f_1191    f_1192    f_1193  \\\n",
              "0    1.537751 -0.352028 -0.114245  ... -0.662884 -0.257091 -1.168413   \n",
              "1    0.729430 -0.216224 -0.000680  ... -1.760084  1.125450 -0.328047   \n",
              "2    0.060111 -1.418468 -0.086128  ... -1.373589 -0.483701 -0.964782   \n",
              "3    0.379008 -1.003667  0.570237  ... -2.794472 -0.763468 -0.789832   \n",
              "4   -0.365174  0.738447  0.054435  ... -3.200223  0.711422 -0.190394   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "797  0.374871  0.806206  0.469159  ...  2.087044 -0.281406  0.854356   \n",
              "798 -0.889185 -0.547437 -2.716407  ...  0.270115 -0.536932  0.556702   \n",
              "799  0.105556  2.473965  2.102029  ... -0.902026  0.370415 -1.169859   \n",
              "800  0.998914  1.702821  0.090807  ... -0.554158 -0.502601  0.142170   \n",
              "801  0.558133  1.482729  1.065893  ...       NaN       NaN       NaN   \n",
              "\n",
              "       f_1194    f_1195    f_1196    f_1197    f_1198    f_1199   id  \n",
              "0    0.223260 -0.482520 -0.085453 -0.382265 -0.539349 -1.682404    1  \n",
              "1   -0.880305 -1.257607  0.964312  2.021104  0.655021 -0.423029    2  \n",
              "2   -0.869555  0.066040 -0.444567 -0.531935 -0.878660  1.099488    3  \n",
              "3   -0.113209 -2.703150 -2.058728  1.070627 -0.458045 -0.435825    4  \n",
              "4    0.337224 -1.656639  0.707360 -0.562290  1.471181 -0.192000    5  \n",
              "..        ...       ...       ...       ...       ...       ...  ...  \n",
              "797  0.350275 -0.784948 -2.347357 -1.066917  1.159733 -1.065897  798  \n",
              "798 -1.732274  0.839805  1.518645  0.303668  0.924748  0.250863  799  \n",
              "799  0.381954  1.242291 -0.889109  0.788108  0.474568  0.628787  800  \n",
              "800  1.494715  0.560818  2.047255 -0.344430 -0.925758  2.174152  801  \n",
              "801       NaN       NaN       NaN       NaN       NaN       NaN  802  \n",
              "\n",
              "[802 rows x 1201 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testdata['id'] = testdf['id']\n",
        "testdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClK2scIBflee"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import regularizers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTo-5izSfy8P"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class TestCallback(Callback):\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        x, y = self.test_data\n",
        "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
        "        print(f'\\nTesting loss: {loss}, acc: {acc}\\n')\n",
        "\n",
        "class ValidationCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs.get('val_loss')\n",
        "        val_acc = logs.get('val_acc')\n",
        "        print(f'\\nValidation loss: {val_loss}, Validation Accuracy: {val_acc}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMlCyku3jZAY"
      },
      "outputs": [],
      "source": [
        "traindf = pd.read_csv(\"train.csv\")\n",
        "testdf = pd.read_csv(\"test.csv\")\n",
        "solexample = pd.read_csv(\"solution_format.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFv9ZYyOg3Xu"
      },
      "outputs": [],
      "source": [
        "# X = traindata\n",
        "# y = trainlabels\n",
        "# ay = aug_df['labels']\n",
        "# aX = aug_df.iloc[:, 1:]\n",
        "flipped_df = traindf.iloc[:, 0:1].join(traindf.iloc[:, 1:][::-1])\n",
        "\n",
        "# Concatenate the original and flipped DataFrames\n",
        "aug_df = pd.concat([traindf, flipped_df], axis=0)\n",
        "\n",
        "X = aug_df.iloc[:, 1:]\n",
        "y = aug_df['labels']\n",
        "ay = aug_df['labels']\n",
        "aX = aug_df.iloc[:, 1:]\n",
        "aX = aX.iloc[:, importantfeatures]\n",
        "\n",
        "\n",
        "rX = traindata.iloc[:, reallyimportantfeatures]\n",
        "ry = trainlabels\n",
        "ray = aug_df['labels']\n",
        "raX = aug_df.iloc[:, 1:]\n",
        "raX = raX.iloc[:, reallyimportantfeatures]\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "aX_train, aX_test, ay_train, ay_test = train_test_split(aX, ay, test_size=0.2, random_state=42)\n",
        "raX_train, raX_test, ray_train, ray_test = train_test_split(raX, ray, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qbyT04gmgxy"
      },
      "outputs": [],
      "source": [
        "oX = traindata\n",
        "oy = trainlabels\n",
        "oX_train, oX_test, oy_train, oy_test = train_test_split(oX, oy, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9gLdBP8L9EK"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3f34HYzlIE1n",
        "outputId": "5ade19f0-4a22-4efe-c1b8-676d4b2127cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for BernoulliNB:\n",
            "Best Parameters:  {'alpha': 0.1, 'binarize': 1.0, 'fit_prior': True}\n",
            "Test set accuracy:  0.8532142857142857\n",
            "\n",
            "Results for BernoulliNB:\n",
            "Best Parameters:  {'alpha': 0.5, 'binarize': 1.0, 'fit_prior': True}\n",
            "Test set accuracy:  0.8508333333333333\n",
            "\n",
            "Results for BernoulliNB:\n",
            "Best Parameters:  {'alpha': 0.1, 'binarize': 1.0, 'fit_prior': True}\n",
            "Test set accuracy:  0.8652380952380953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the classifiers and their respective parameter grids\n",
        "classifiers = {\n",
        "    # 'GaussianNB': GaussianNB(),\n",
        "    # 'MultinomialNB': MultinomialNB(),\n",
        "    'BernoulliNB': BernoulliNB()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    # 'GaussianNB': {'var_smoothing': np.logspace(-10, -8, 10)},\n",
        "    # 'MultinomialNB': {'alpha': np.linspace(0.5, 1.5, 6)},\n",
        "    'BernoulliNB': {\n",
        "    'alpha': [0.1, 0.5, 1.0],\n",
        "    'binarize': [0.0, 0.5, 1.0],\n",
        "    'fit_prior': [True, False],}\n",
        "    # 'class_prior': [None, [0.3, 0.7]]}\n",
        "}\n",
        "\n",
        "# Perform grid search for each type of Naive Bayes classifier\n",
        "# for data in [(aX_train,aY_train), (raX_train,aX_train), (X_train,aX_train)]:\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(aX_train)\n",
        "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[classifier_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(scaler.transform(aX_train), ay_train)\n",
        "\n",
        "    # Print results for the current classifier\n",
        "    print(f\"Results for {classifier_name}:\")\n",
        "    print(\"Best Parameters: \", grid_search.best_params_)\n",
        "    print(\"Test set accuracy: \", grid_search.score(aX_train, ay_train))\n",
        "    print()\n",
        "\n",
        "\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(raX_train)\n",
        "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[classifier_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(scaler.transform(raX_train), ray_train)\n",
        "\n",
        "    # Print results for the current classifier\n",
        "    print(f\"Results for {classifier_name}:\")\n",
        "    print(\"Best Parameters: \", grid_search.best_params_)\n",
        "    print(\"Test set accuracy: \", grid_search.score(raX_train, ray_train))\n",
        "    print()\n",
        "\n",
        "\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[classifier_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(scaler.transform(X_train), y_train)\n",
        "\n",
        "    # Print results for the current classifier\n",
        "    print(f\"Results for {classifier_name}:\")\n",
        "    print(\"Best Parameters: \", grid_search.best_params_)\n",
        "    print(\"Test set accuracy: \", grid_search.score(X_test, y_test))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nibuPaueX-RR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw7C4-wwUKI1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n",
        "\n",
        "# Define the classifiers and their respective parameter grids\n",
        "classifiers = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    # 'RadiusNeighbors': RadiusNeighborsClassifier(),\n",
        "    # 'NearestCentroid': NearestCentroid()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'KNN': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'], 'p': [1, 2], 'metric': ['euclidean', 'manhattan']}\n",
        "    # 'RadiusNeighbors': {'radius': [0.5, 1.0, 1.5], 'weights': ['uniform', 'distance']},\n",
        "    # 'NearestCentroid': {'shrink_threshold': [0.1, 0.5, 1.0]}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J_VhvejR--V",
        "outputId": "543ea26c-f1be-4c96-cbfd-b0ec4c039783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for KNN:\n",
            "Best Parameters:  {'metric': 'manhattan', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
            "Test set accuracy:  0.9742857142857143\n",
            "\n",
            "Results for KNN:\n",
            "Best Parameters:  {'metric': 'manhattan', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
            "Test set accuracy:  1.0\n",
            "\n",
            "Results for KNN:\n",
            "Best Parameters:  {'metric': 'euclidean', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
            "Test set accuracy:  0.9676190476190476\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Perform grid search for each type of nearest neighbors classifier\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "    scaler = StandardScaler()\n",
        "    # scaler.fit(raX_train)\n",
        "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[classifier_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit((raX_train), ray_train)\n",
        "\n",
        "    # Print results for the current classifier\n",
        "    print(f\"Results for {classifier_name}:\")\n",
        "    print(\"Best Parameters: \", grid_search.best_params_)\n",
        "    print(\"Test set accuracy: \", grid_search.score(raX_test, ray_test))\n",
        "    print()\n",
        "\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(aX_train)\n",
        "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[classifier_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit((aX_test), ay_test)\n",
        "\n",
        "    # Print results for the current classifier\n",
        "    print(f\"Results for {classifier_name}:\")\n",
        "    print(\"Best Parameters: \", grid_search.best_params_)\n",
        "    print(\"Test set accuracy: \", grid_search.score(aX_test, ay_test))\n",
        "    print()\n",
        "\n",
        "\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[classifier_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit((X_train), y_train)\n",
        "\n",
        "    # Print results for the current classifier\n",
        "    print(f\"Results for {classifier_name}:\")\n",
        "    print(\"Best Parameters: \", grid_search.best_params_)\n",
        "    print(\"Test set accuracy: \", grid_search.score(X_test, y_test))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7dXeUk1UNSd"
      },
      "outputs": [],
      "source": [
        "sub = testdf.iloc[:, 1:]\n",
        "sub1 = sub.iloc[:, importantfeatures]\n",
        "sub2 = sub.iloc[:, reallyimportantfeatures]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuwOZYv8WY0C"
      },
      "outputs": [],
      "source": [
        "KNNbest = KNeighborsClassifier(metric='manhattan', n_neighbors=7, p=1, weights='distance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "7UBbE6DIWpnP",
        "outputId": "52287109-5cbd-4854-d0a8-a660af668e57"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7, p=1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric='manhattan', n_neighbors=7, p=1, weights='distance')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "KNNbest.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "vcFuu8nHYLFG",
        "outputId": "9e7fd1c6-3ffc-43ef-8c1a-d6937475f775"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB(alpha=0.1, binarize=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB(alpha=0.1, binarize=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "BernoulliNB(alpha=0.1, binarize=1)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "NBbest = BernoulliNB(alpha=0.1, binarize=1, fit_prior=True)\n",
        "NBbest.fit(scaler.transform(X_train), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK_IAo2RW2eG"
      },
      "outputs": [],
      "source": [
        "testdf['labels'] = KNNbest.predict(sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FXkpS8SW6tn"
      },
      "outputs": [],
      "source": [
        "submission = testdf[['id', 'labels']]\n",
        "\n",
        "submission.to_csv(\"KNN_gridsearch_og.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hytwtbU3YJ4n"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "rdX_hFF2c2eQ",
        "outputId": "cd176309-7e93-4126-bc62-8999069468b9"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-0a192dfbb5b4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgboost_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgboost_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                                                     dtrain.handle))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "xgboost_model = XGBClassifier()\n",
        "xgboost_model.fit(X_train, y_train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdGlJLSZR1ff",
        "outputId": "a75697ca-51ce-4877-e5fe-e46acef4ead9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 150}\n",
            "Accuracy: 0.9761904761904762\n"
          ]
        }
      ],
      "source": [
        "#gridsearching XGBOOST FOR BEST\n",
        "\n",
        "xgboost_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 150],\n",
        "    'learning_rate': [0.05],\n",
        "    'max_depth': [6, 12],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgboost_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "# Define GridSearchCV object\n",
        "\n",
        "# Fit the GridSearchCV object\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Get the best estimator and make predictions\n",
        "best_xgboost_model = grid_search.best_estimator_\n",
        "predictions = best_xgboost_model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "# for classifier_name, classifier in classifiers.items():\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRB98j9LScaF"
      },
      "outputs": [],
      "source": [
        "#test Stacking\n",
        "meta_model = KNeighborsClassifier()\n",
        "\n",
        "stacking_classifier = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgboost', XGBClassifier()),\n",
        "        ('knn', KNeighborsClassifier(metric='manhattan', n_neighbors=7, p=1, weights='distance')),\n",
        "        ('bernoulliNB', GaussianNB())\n",
        "    ],\n",
        "    final_estimator=KNeighborsClassifier(metric='manhattan', n_neighbors=7, p=1, weights='distance')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qA9q2bgLdrJ2",
        "outputId": "1289d0f1-c06c-4656-cef5-2e6c22df5318"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;xgboost&#x27;,\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel=None,\n",
              "                                              colsample_bynode=None,\n",
              "                                              colsample_bytree=None,\n",
              "                                              early_stopping_rounds=None,\n",
              "                                              enable_categorical=False,\n",
              "                                              eval_metric=None,\n",
              "                                              feature_types=None, gamma=None,\n",
              "                                              gpu_id=None, grow_policy=None,\n",
              "                                              importance_type=None,\n",
              "                                              interaction_constraints=None,\n",
              "                                              learn...\n",
              "                                              min_child_weight=None,\n",
              "                                              missing=nan,\n",
              "                                              monotone_constraints=None,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              num_parallel_tree=None,\n",
              "                                              predictor=None, random_state=None, ...)),\n",
              "                               (&#x27;knn&#x27;,\n",
              "                                KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
              "                                                     n_neighbors=7, p=1,\n",
              "                                                     weights=&#x27;distance&#x27;)),\n",
              "                               (&#x27;bernoulliNB&#x27;, GaussianNB())],\n",
              "                   final_estimator=KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
              "                                                        n_neighbors=7, p=1,\n",
              "                                                        weights=&#x27;distance&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;xgboost&#x27;,\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel=None,\n",
              "                                              colsample_bynode=None,\n",
              "                                              colsample_bytree=None,\n",
              "                                              early_stopping_rounds=None,\n",
              "                                              enable_categorical=False,\n",
              "                                              eval_metric=None,\n",
              "                                              feature_types=None, gamma=None,\n",
              "                                              gpu_id=None, grow_policy=None,\n",
              "                                              importance_type=None,\n",
              "                                              interaction_constraints=None,\n",
              "                                              learn...\n",
              "                                              min_child_weight=None,\n",
              "                                              missing=nan,\n",
              "                                              monotone_constraints=None,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              num_parallel_tree=None,\n",
              "                                              predictor=None, random_state=None, ...)),\n",
              "                               (&#x27;knn&#x27;,\n",
              "                                KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
              "                                                     n_neighbors=7, p=1,\n",
              "                                                     weights=&#x27;distance&#x27;)),\n",
              "                               (&#x27;bernoulliNB&#x27;, GaussianNB())],\n",
              "                   final_estimator=KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
              "                                                        n_neighbors=7, p=1,\n",
              "                                                        weights=&#x27;distance&#x27;))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>bernoulliNB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "StackingClassifier(estimators=[('xgboost',\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel=None,\n",
              "                                              colsample_bynode=None,\n",
              "                                              colsample_bytree=None,\n",
              "                                              early_stopping_rounds=None,\n",
              "                                              enable_categorical=False,\n",
              "                                              eval_metric=None,\n",
              "                                              feature_types=None, gamma=None,\n",
              "                                              gpu_id=None, grow_policy=None,\n",
              "                                              importance_type=None,\n",
              "                                              interaction_constraints=None,\n",
              "                                              learn...\n",
              "                                              min_child_weight=None,\n",
              "                                              missing=nan,\n",
              "                                              monotone_constraints=None,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              num_parallel_tree=None,\n",
              "                                              predictor=None, random_state=None, ...)),\n",
              "                               ('knn',\n",
              "                                KNeighborsClassifier(metric='manhattan',\n",
              "                                                     n_neighbors=7, p=1,\n",
              "                                                     weights='distance')),\n",
              "                               ('bernoulliNB', GaussianNB())],\n",
              "                   final_estimator=KNeighborsClassifier(metric='manhattan',\n",
              "                                                        n_neighbors=7, p=1,\n",
              "                                                        weights='distance'))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stacking_classifier.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfHaolCRht9e"
      },
      "outputs": [],
      "source": [
        "testdf['labels'] = stacking_classifier.predict(sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yvq-gsxiA1m"
      },
      "outputs": [],
      "source": [
        "submission = testdf[['id', 'labels']]\n",
        "\n",
        "submission.to_csv(\"stacked3.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kn9FlntNdGv"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "testknn=KNeighborsClassifier(n_neighbors=12, weights='uniform', p=1, algorithm='auto', metric='manhattan')\n",
        "testxgb=XGBClassifier()\n",
        "# testnb=GaussianNB()\n",
        "testbnb = BernoulliNB(alpha=0.1, binarize=1.0, fit_prior=True)\n",
        "testada=AdaBoostClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0G4qLWDZ5Bj",
        "outputId": "a415552b-3405-4a91-f8ec-9a196d5335f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (Stacking Ensemble - KNN, Naive Bayes, XGB): 0.9809523809523809\n"
          ]
        }
      ],
      "source": [
        "stacking_ensemble = StackingClassifier(\n",
        "  estimators= [\n",
        "    ('knn', testknn), ('nb', testbnb), ('xgb', testxgb)]\n",
        "    # ('adaboost', adaboost_pipeline),\n",
        "    # ('gradient', gradient_pipeline)]\n",
        "    , final_estimator=testknn\n",
        ")\n",
        "stacking_ensemble.fit (X_train, y_train)\n",
        "accuracy = stacking_ensemble.score(X_test, y_test)\n",
        "print (\"Accuracy (Stacking Ensemble - KNN, Naive Bayes, XGB):\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GDeZJgKAxefV",
        "outputId": "1d315500-41aa-4b7b-ffc1-565978eb8553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (Stacking Ensemble - KNN, Naive Bayes, XGB): 0.7533333333333333\n"
          ]
        }
      ],
      "source": [
        "stacking_ensemble = StackingClassifier(\n",
        "  estimators= [\n",
        "    ('knn', testknn), ('nb', testbnb), ('xgb', testxgb)]\n",
        "    # ('adaboost', adaboost_pipeline),\n",
        "    # ('gradient', gradient_pipeline)]\n",
        "    , final_estimator=testbnb\n",
        ")\n",
        "stacking_ensemble.fit (X_train, y_train)\n",
        "accuracy = stacking_ensemble.score(X_test, y_test)\n",
        "print (\"Accuracy (Stacking Ensemble - KNN, Naive Bayes, XGB):\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YXvoEgqqxg8k",
        "outputId": "edec7049-73fa-4bae-ceec-3c7f369f55bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (Stacking Ensemble - KNN, Naive Bayes, XGB): 0.9776190476190476\n"
          ]
        }
      ],
      "source": [
        "stacking_ensemble = StackingClassifier(\n",
        "  estimators= [\n",
        "    ('knn', testknn), ('nb', testbnb), ('xgb', testxgb)]\n",
        "    # ('adaboost', adaboost_pipeline),\n",
        "    # ('gradient', gradient_pipeline)]\n",
        "    , final_estimator=testxgb\n",
        ")\n",
        "stacking_ensemble.fit (X_train, y_train)\n",
        "accuracy = stacking_ensemble.score(X_test, y_test)\n",
        "print (\"Accuracy (Stacking Ensemble - KNN, Naive Bayes, XGB):\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "ddsxv3fGlolO",
        "outputId": "c3462f75-2b16-47cd-875e-32b3429008d2"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-fffb02d9ed8f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacking_ensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \"\"\"\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;31m# Handle the multilabel-indicator case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sk_visual_block_with_final_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mPrediction\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sk_visual_block_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;34m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         predictions = [\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_method_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         predictions = [\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_method_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"drop\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;31m# the weighting so we do not compute them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    822\u001b[0m         )\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \"\"\"\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             return ArgKmin64.compute(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_original_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "testdf['labels'] = stacking_ensemble.predict(sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jKl-DH2l9Yh"
      },
      "outputs": [],
      "source": [
        "submission = testdf[['id', 'labels']]\n",
        "\n",
        "submission.to_csv(\"stacked5_friendver.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_sHHO7WNsQx"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiByM8UmUmvi",
        "outputId": "d786567e-0fca-497f-ba96-f2f6e8b0d096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for KNN:\n",
            "Best Parameters:  {'metric': 'manhattan', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
            "Test set accuracy:  0.8557142857142858\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for classifier_name, classifier in classifiers.items():\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(aX_train)\n",
        "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[classifier_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(scaler.transform(aX_train), ay_train)\n",
        "\n",
        "    # Print results for the current classifier\n",
        "    print(f\"Results for {classifier_name}:\")\n",
        "    print(\"Best Parameters: \", grid_search.best_params_)\n",
        "    print(\"Test set accuracy: \", grid_search.score(aX_test, ay_test))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "diHydrroUOwW",
        "outputId": "731939d1-e216-42e4-8e07-c82d534ea490"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7, p=1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric='manhattan', n_neighbors=7, p=1, weights='distance')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "    knnClassifier = KNeighborsClassifier(n_neighbors=7, metric='manhattan', p=1, weights='distance')\n",
        "    knnClassifier.fit(aX_train, ay_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc1ow46xUO9I"
      },
      "outputs": [],
      "source": [
        "knnClassifier.predict(aX_test,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7naZUGq8hWV",
        "outputId": "f26968f5-04ab-4fc5-a58e-4497dec068d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "252/263 [===========================>..] - ETA: 0s - loss: 1.3579 - accuracy: 0.8702\n",
            "Testing loss: 0.6461803317070007, acc: 0.9147619009017944\n",
            "\n",
            "263/263 [==============================] - 2s 5ms/step - loss: 1.3300 - accuracy: 0.8715\n",
            "Epoch 2/15\n",
            "253/263 [===========================>..] - ETA: 0s - loss: 0.4415 - accuracy: 0.9460\n",
            "Testing loss: 0.3839651346206665, acc: 0.9309523701667786\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.4394 - accuracy: 0.9452\n",
            "Epoch 3/15\n",
            "261/263 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.9662\n",
            "Testing loss: 0.30883923172950745, acc: 0.949999988079071\n",
            "\n",
            "263/263 [==============================] - 2s 6ms/step - loss: 0.2875 - accuracy: 0.9662\n",
            "Epoch 4/15\n",
            "258/263 [============================>.] - ETA: 0s - loss: 0.2243 - accuracy: 0.9817\n",
            "Testing loss: 0.28051379323005676, acc: 0.9571428298950195\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.2243 - accuracy: 0.9813\n",
            "Epoch 5/15\n",
            "255/263 [============================>.] - ETA: 0s - loss: 0.1975 - accuracy: 0.9857\n",
            "Testing loss: 0.25816774368286133, acc: 0.9609524011611938\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1975 - accuracy: 0.9857\n",
            "Epoch 6/15\n",
            "257/263 [============================>.] - ETA: 0s - loss: 0.1869 - accuracy: 0.9843\n",
            "Testing loss: 0.24418288469314575, acc: 0.9661904573440552\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1868 - accuracy: 0.9844\n",
            "Epoch 7/15\n",
            "258/263 [============================>.] - ETA: 0s - loss: 0.1629 - accuracy: 0.9909\n",
            "Testing loss: 0.23155446350574493, acc: 0.9609524011611938\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1628 - accuracy: 0.9907\n",
            "Epoch 8/15\n",
            "260/263 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9903\n",
            "Testing loss: 0.22322452068328857, acc: 0.9676190614700317\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1517 - accuracy: 0.9902\n",
            "Epoch 9/15\n",
            "255/263 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.9915\n",
            "Testing loss: 0.22473447024822235, acc: 0.961904764175415\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9910\n",
            "Epoch 10/15\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9902\n",
            "Testing loss: 0.21464508771896362, acc: 0.9690476059913635\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1361 - accuracy: 0.9902\n",
            "Epoch 11/15\n",
            "246/263 [===========================>..] - ETA: 0s - loss: 0.1389 - accuracy: 0.9907\n",
            "Testing loss: 0.21517255902290344, acc: 0.9599999785423279\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9905\n",
            "Epoch 12/15\n",
            "254/263 [===========================>..] - ETA: 0s - loss: 0.1322 - accuracy: 0.9905\n",
            "Testing loss: 0.21948276460170746, acc: 0.9599999785423279\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1323 - accuracy: 0.9904\n",
            "Epoch 13/15\n",
            "260/263 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9959\n",
            "Testing loss: 0.18991388380527496, acc: 0.9666666388511658\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1132 - accuracy: 0.9960\n",
            "Epoch 14/15\n",
            "255/263 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.9955\n",
            "Testing loss: 0.19964337348937988, acc: 0.9647619128227234\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9954\n",
            "Epoch 15/15\n",
            "258/263 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.9903\n",
            "Testing loss: 0.20134171843528748, acc: 0.9642857313156128\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1169 - accuracy: 0.9901\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f95192394e0>"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# high importance prediction\n",
        "\n",
        "amodel = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "amodel.add(Dense(64, activation='relu', input_shape=(raX_train.shape[1],), kernel_regularizer=regularizers.l2(0.01),\n",
        "                activity_regularizer=regularizers.l1(0.01)))\n",
        "amodel.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01),))\n",
        "                #activity_regularizer=regularizers.l1(0.01)))\n",
        "amodel.add(Dense(1, activation='sigmoid'))  # Binary classification => sigmoid activation function\n",
        "\n",
        "# Compile the model\n",
        "amodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "amodel.fit(raX_train, ray_train, epochs=15, batch_size=32, callbacks=[TestCallback((raX_test, ray_test))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xim3KJH0gwsV",
        "outputId": "decbb13c-0370-4c7d-8d4d-f66c1cfed2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "253/263 [===========================>..] - ETA: 0s - loss: 1.3503 - accuracy: 0.8668\n",
            "Testing loss: 0.6426070332527161, acc: 0.9085714221000671\n",
            "\n",
            "263/263 [==============================] - 2s 6ms/step - loss: 1.3258 - accuracy: 0.8682\n",
            "Epoch 2/15\n",
            "250/263 [===========================>..] - ETA: 0s - loss: 0.4500 - accuracy: 0.9442\n",
            "Testing loss: 0.39204034209251404, acc: 0.9409523606300354\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.4462 - accuracy: 0.9440\n",
            "Epoch 3/15\n",
            "253/263 [===========================>..] - ETA: 0s - loss: 0.2871 - accuracy: 0.9701\n",
            "Testing loss: 0.3225785195827484, acc: 0.9519047737121582\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.2871 - accuracy: 0.9695\n",
            "Epoch 4/15\n",
            "252/263 [===========================>..] - ETA: 0s - loss: 0.2378 - accuracy: 0.9785\n",
            "Testing loss: 0.29058635234832764, acc: 0.9561904668807983\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.2371 - accuracy: 0.9785\n",
            "Epoch 5/15\n",
            "253/263 [===========================>..] - ETA: 0s - loss: 0.2006 - accuracy: 0.9838\n",
            "Testing loss: 0.27870965003967285, acc: 0.950952410697937\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.2004 - accuracy: 0.9838\n",
            "Epoch 6/15\n",
            "259/263 [============================>.] - ETA: 0s - loss: 0.1831 - accuracy: 0.9861\n",
            "Testing loss: 0.2778979241847992, acc: 0.9609524011611938\n",
            "\n",
            "263/263 [==============================] - 2s 6ms/step - loss: 0.1832 - accuracy: 0.9861\n",
            "Epoch 7/15\n",
            "257/263 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9852\n",
            "Testing loss: 0.2415943145751953, acc: 0.9685714244842529\n",
            "\n",
            "263/263 [==============================] - 2s 8ms/step - loss: 0.1754 - accuracy: 0.9854\n",
            "Epoch 8/15\n",
            "259/263 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9935\n",
            "Testing loss: 0.23373360931873322, acc: 0.9671428799629211\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1478 - accuracy: 0.9935\n",
            "Epoch 9/15\n",
            "262/263 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9945\n",
            "Testing loss: 0.22759440541267395, acc: 0.9676190614700317\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1301 - accuracy: 0.9945\n",
            "Epoch 10/15\n",
            "250/263 [===========================>..] - ETA: 0s - loss: 0.1508 - accuracy: 0.9843\n",
            "Testing loss: 0.29022201895713806, acc: 0.9495238065719604\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9836\n",
            "Epoch 11/15\n",
            "257/263 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9803\n",
            "Testing loss: 0.26603958010673523, acc: 0.9576190710067749\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1736 - accuracy: 0.9805\n",
            "Epoch 12/15\n",
            "262/263 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.9943\n",
            "Testing loss: 0.24021294713020325, acc: 0.9685714244842529\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1356 - accuracy: 0.9943\n",
            "Epoch 13/15\n",
            "257/263 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9988\n",
            "Testing loss: 0.20550155639648438, acc: 0.9657142758369446\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.1016 - accuracy: 0.9988\n",
            "Epoch 14/15\n",
            "260/263 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9992\n",
            "Testing loss: 0.19063600897789001, acc: 0.9700000286102295\n",
            "\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9992\n",
            "Epoch 15/15\n",
            "262/263 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9945\n",
            "Testing loss: 0.27096471190452576, acc: 0.9338095188140869\n",
            "\n",
            "263/263 [==============================] - 2s 6ms/step - loss: 0.0929 - accuracy: 0.9944\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9519354e80>"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bmodel = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "bmodel.add(Dense(64, activation='relu', input_shape=(aX_train.shape[1],), kernel_regularizer=regularizers.l2(0.01),\n",
        "                activity_regularizer=regularizers.l1(0.01)))\n",
        "bmodel.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01),))\n",
        "                #activity_regularizer=regularizers.l1(0.01)))\n",
        "bmodel.add(Dense(1, activation='sigmoid'))  # Binary classification => sigmoid activation function\n",
        "\n",
        "# Compile the model\n",
        "bmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "bmodel.fit(aX_train, ay_train, epochs=15, batch_size=32, callbacks=[TestCallback((aX_test, ay_test))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LEGOrcEfkaB",
        "outputId": "7064fc37-210c-4672-e262-8db4401434a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "128/132 [============================>.] - ETA: 0s - loss: 1.7292 - accuracy: 0.8271\n",
            "Testing loss: 1.093595027923584, acc: 0.8600000143051147\n",
            "\n",
            "132/132 [==============================] - 3s 10ms/step - loss: 1.7145 - accuracy: 0.8274\n",
            "Epoch 2/15\n",
            "124/132 [===========================>..] - ETA: 0s - loss: 0.7461 - accuracy: 0.9229\n",
            "Testing loss: 0.7331593036651611, acc: 0.8495237827301025\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.7400 - accuracy: 0.9214\n",
            "Epoch 3/15\n",
            "122/132 [==========================>...] - ETA: 0s - loss: 0.4476 - accuracy: 0.9524\n",
            "Testing loss: 0.6727089881896973, acc: 0.822857141494751\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.4498 - accuracy: 0.9488\n",
            "Epoch 4/15\n",
            "123/132 [==========================>...] - ETA: 0s - loss: 0.3433 - accuracy: 0.9695\n",
            "Testing loss: 0.6666585803031921, acc: 0.8361904621124268\n",
            "\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.3420 - accuracy: 0.9695\n",
            "Epoch 5/15\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.2602 - accuracy: 0.9896\n",
            "Testing loss: 0.6741208434104919, acc: 0.8219047784805298\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.2598 - accuracy: 0.9893\n",
            "Epoch 6/15\n",
            "124/132 [===========================>..] - ETA: 0s - loss: 0.2112 - accuracy: 0.9962\n",
            "Testing loss: 0.6699917912483215, acc: 0.8199999928474426\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.2110 - accuracy: 0.9952\n",
            "Epoch 7/15\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.2087 - accuracy: 0.9878\n",
            "Testing loss: 0.6567630767822266, acc: 0.8361904621124268\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.2084 - accuracy: 0.9876\n",
            "Epoch 8/15\n",
            "121/132 [==========================>...] - ETA: 0s - loss: 0.2341 - accuracy: 0.9768\n",
            "Testing loss: 0.6813929677009583, acc: 0.8209523558616638\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.2354 - accuracy: 0.9757\n",
            "Epoch 9/15\n",
            "123/132 [==========================>...] - ETA: 0s - loss: 0.2232 - accuracy: 0.9817\n",
            "Testing loss: 0.6710643172264099, acc: 0.8285714387893677\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.2234 - accuracy: 0.9812\n",
            "Epoch 10/15\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.1844 - accuracy: 0.9930\n",
            "Testing loss: 0.6782031655311584, acc: 0.8285714387893677\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.1847 - accuracy: 0.9929\n",
            "Epoch 11/15\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.1528 - accuracy: 0.9970\n",
            "Testing loss: 0.6384623050689697, acc: 0.8333333134651184\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.1526 - accuracy: 0.9971\n",
            "Epoch 12/15\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.1279 - accuracy: 0.9985\n",
            "Testing loss: 0.5934504866600037, acc: 0.8399999737739563\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.1285 - accuracy: 0.9983\n",
            "Epoch 13/15\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.1110 - accuracy: 0.9990\n",
            "Testing loss: 0.581784188747406, acc: 0.8333333134651184\n",
            "\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.1107 - accuracy: 0.9990\n",
            "Epoch 14/15\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.1003 - accuracy: 0.9990\n",
            "Testing loss: 0.5793375968933105, acc: 0.8342857360839844\n",
            "\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.1003 - accuracy: 0.9990\n",
            "Epoch 15/15\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9990\n",
            "Testing loss: 0.5885293483734131, acc: 0.8304761648178101\n",
            "\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.0959 - accuracy: 0.9990\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9512f63910>"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cmodel = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "cmodel.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l2(0.01),\n",
        "                activity_regularizer=regularizers.l1(0.01)))\n",
        "cmodel.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01),))\n",
        "                #activity_regularizer=regularizers.l1(0.01)))\n",
        "cmodel.add(Dense(1, activation='sigmoid'))  # Binary classification => sigmoid activation function\n",
        "\n",
        "# Compile the model\n",
        "cmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cmodel.fit(X_train, y_train, epochs=15, batch_size=32, callbacks=[TestCallback((X_test, y_test))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNgmZWo1pB_C",
        "outputId": "14a81d89-fe10-45c3-c83e-5d1b2e5061ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "v7jaumM9jcLT",
        "outputId": "0acdb7d7-8bd3-4601-b24c-5142a9f2f68d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-70118b98-d08a-421c-9a07-70b6e54875d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>f_11</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1182</th>\n",
              "      <th>f_1183</th>\n",
              "      <th>f_1186</th>\n",
              "      <th>f_1187</th>\n",
              "      <th>f_1191</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>-1.625735</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>-0.114245</td>\n",
              "      <td>1.106692</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.077703</td>\n",
              "      <td>-0.246397</td>\n",
              "      <td>-0.013587</td>\n",
              "      <td>-0.960774</td>\n",
              "      <td>-0.662884</td>\n",
              "      <td>-0.257091</td>\n",
              "      <td>-1.168413</td>\n",
              "      <td>0.223260</td>\n",
              "      <td>-0.085453</td>\n",
              "      <td>-0.382265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>0.513516</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>-0.000680</td>\n",
              "      <td>0.631447</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100701</td>\n",
              "      <td>-0.803960</td>\n",
              "      <td>0.065069</td>\n",
              "      <td>0.686565</td>\n",
              "      <td>-1.760084</td>\n",
              "      <td>1.125450</td>\n",
              "      <td>-0.328047</td>\n",
              "      <td>-0.880305</td>\n",
              "      <td>0.964312</td>\n",
              "      <td>2.021104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.904994</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>-0.086128</td>\n",
              "      <td>0.253428</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.438368</td>\n",
              "      <td>0.427841</td>\n",
              "      <td>-0.205051</td>\n",
              "      <td>-1.388523</td>\n",
              "      <td>-1.373589</td>\n",
              "      <td>-0.483701</td>\n",
              "      <td>-0.964782</td>\n",
              "      <td>-0.869555</td>\n",
              "      <td>-0.444567</td>\n",
              "      <td>-0.531935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>-0.327977</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>0.570237</td>\n",
              "      <td>0.389538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.362197</td>\n",
              "      <td>0.281699</td>\n",
              "      <td>0.524736</td>\n",
              "      <td>0.387674</td>\n",
              "      <td>-2.794472</td>\n",
              "      <td>-0.763468</td>\n",
              "      <td>-0.789832</td>\n",
              "      <td>-0.113209</td>\n",
              "      <td>-2.058728</td>\n",
              "      <td>1.070627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>1.044211</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>0.054435</td>\n",
              "      <td>-1.332867</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.383635</td>\n",
              "      <td>-0.864941</td>\n",
              "      <td>-0.296326</td>\n",
              "      <td>0.452763</td>\n",
              "      <td>-3.200223</td>\n",
              "      <td>0.711422</td>\n",
              "      <td>-0.190394</td>\n",
              "      <td>0.337224</td>\n",
              "      <td>0.707360</td>\n",
              "      <td>-0.562290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.319077</td>\n",
              "      <td>0.849589</td>\n",
              "      <td>0.822723</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.910127</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>0.204808</td>\n",
              "      <td>0.863022</td>\n",
              "      <td>...</td>\n",
              "      <td>0.836156</td>\n",
              "      <td>-0.574303</td>\n",
              "      <td>0.016746</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-2.226556</td>\n",
              "      <td>-0.090717</td>\n",
              "      <td>-1.393713</td>\n",
              "      <td>-0.896694</td>\n",
              "      <td>-0.856395</td>\n",
              "      <td>0.876455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>1.005737</td>\n",
              "      <td>-0.064755</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>0.712760</td>\n",
              "      <td>-0.785929</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>1.107152</td>\n",
              "      <td>1.152225</td>\n",
              "      <td>...</td>\n",
              "      <td>1.129689</td>\n",
              "      <td>-0.154902</td>\n",
              "      <td>0.757833</td>\n",
              "      <td>-1.247931</td>\n",
              "      <td>-1.270468</td>\n",
              "      <td>-0.932417</td>\n",
              "      <td>-1.169053</td>\n",
              "      <td>-0.008414</td>\n",
              "      <td>-0.323927</td>\n",
              "      <td>1.163494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>1.252086</td>\n",
              "      <td>1.223561</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.987156</td>\n",
              "      <td>0.239435</td>\n",
              "      <td>-1.158309</td>\n",
              "      <td>1.237823</td>\n",
              "      <td>-1.272410</td>\n",
              "      <td>0.767154</td>\n",
              "      <td>-0.630589</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.429300</td>\n",
              "      <td>0.125333</td>\n",
              "      <td>1.009620</td>\n",
              "      <td>-1.129783</td>\n",
              "      <td>-1.386512</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>-1.243885</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>1.594391</td>\n",
              "      <td>1.252086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>1.042624</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.066538</td>\n",
              "      <td>1.030667</td>\n",
              "      <td>1.162195</td>\n",
              "      <td>-1.396612</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-1.025944</td>\n",
              "      <td>0.982839</td>\n",
              "      <td>1.078495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.970882</td>\n",
              "      <td>-1.611839</td>\n",
              "      <td>0.588257</td>\n",
              "      <td>-0.870502</td>\n",
              "      <td>-1.193343</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>-0.081338</td>\n",
              "      <td>-0.978116</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.090452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>-1.319572</td>\n",
              "      <td>-0.485173</td>\n",
              "      <td>-0.098500</td>\n",
              "      <td>2.323293</td>\n",
              "      <td>-0.139202</td>\n",
              "      <td>0.084661</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>1.427840</td>\n",
              "      <td>-0.403768</td>\n",
              "      <td>-0.057797</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003256</td>\n",
              "      <td>-1.746947</td>\n",
              "      <td>-0.179905</td>\n",
              "      <td>-0.078149</td>\n",
              "      <td>-0.220607</td>\n",
              "      <td>-0.871845</td>\n",
              "      <td>0.654495</td>\n",
              "      <td>0.430631</td>\n",
              "      <td>-0.118851</td>\n",
              "      <td>0.471334</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 717 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70118b98-d08a-421c-9a07-70b6e54875d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70118b98-d08a-421c-9a07-70b6e54875d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70118b98-d08a-421c-9a07-70b6e54875d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_6       f_7  \\\n",
              "0    -3.388242  0.868285 -0.427619 -0.678964 -1.625735  1.243040  1.537751   \n",
              "1    -0.496920  0.952381  0.989040  0.451422  0.513516 -1.124326  0.729430   \n",
              "2     1.128369 -0.537951  2.544358  1.165254 -1.904994 -0.495768  0.060111   \n",
              "3     0.051253  1.746814  0.681177  1.844524 -0.327977 -0.085519  0.379008   \n",
              "4     1.423209 -0.983594 -1.694170  1.197507  1.044211 -0.298612 -0.365174   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2245  0.889888 -0.319077  0.849589  0.822723  0.876455  0.876455 -0.910127   \n",
              "2246  1.005737 -0.064755  1.163494  1.163494  1.163494  0.712760 -0.785929   \n",
              "2247  1.252086  1.223561  0.153859 -0.987156  0.239435 -1.158309  1.237823   \n",
              "2248  1.042624 -0.129166  1.066538  1.030667  1.162195 -1.396612  0.014319   \n",
              "2249 -1.319572 -0.485173 -0.098500  2.323293 -0.139202  0.084661 -0.566577   \n",
              "\n",
              "           f_8       f_9      f_11  ...    f_1182    f_1183    f_1186  \\\n",
              "0    -0.352028 -0.114245  1.106692  ... -1.077703 -0.246397 -0.013587   \n",
              "1    -0.216224 -0.000680  0.631447  ...  0.100701 -0.803960  0.065069   \n",
              "2    -1.418468 -0.086128  0.253428  ... -2.438368  0.427841 -0.205051   \n",
              "3    -1.003667  0.570237  0.389538  ...  0.362197  0.281699  0.524736   \n",
              "4     0.738447  0.054435 -1.332867  ... -0.383635 -0.864941 -0.296326   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2245  0.889888  0.204808  0.863022  ...  0.836156 -0.574303  0.016746   \n",
              "2246 -1.225394  1.107152  1.152225  ...  1.129689 -0.154902  0.757833   \n",
              "2247 -1.272410  0.767154 -0.630589  ... -1.429300  0.125333  1.009620   \n",
              "2248 -1.025944  0.982839  1.078495  ...  0.970882 -1.611839  0.588257   \n",
              "2249  1.427840 -0.403768 -0.057797  ...  0.003256 -1.746947 -0.179905   \n",
              "\n",
              "        f_1187    f_1191    f_1192    f_1193    f_1194    f_1196    f_1197  \n",
              "0    -0.960774 -0.662884 -0.257091 -1.168413  0.223260 -0.085453 -0.382265  \n",
              "1     0.686565 -1.760084  1.125450 -0.328047 -0.880305  0.964312  2.021104  \n",
              "2    -1.388523 -1.373589 -0.483701 -0.964782 -0.869555 -0.444567 -0.531935  \n",
              "3     0.387674 -2.794472 -0.763468 -0.789832 -0.113209 -2.058728  1.070627  \n",
              "4     0.452763 -3.200223  0.711422 -0.190394  0.337224  0.707360 -0.562290  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2245  0.889888 -2.226556 -0.090717 -1.393713 -0.896694 -0.856395  0.876455  \n",
              "2246 -1.247931 -1.270468 -0.932417 -1.169053 -0.008414 -0.323927  1.163494  \n",
              "2247 -1.129783 -1.386512  0.809943 -1.243885  0.153859  1.594391  1.252086  \n",
              "2248 -0.870502 -1.193343  0.086061 -0.081338 -0.978116 -0.129166  1.090452  \n",
              "2249 -0.078149 -0.220607 -0.871845  0.654495  0.430631 -0.118851  0.471334  \n",
              "\n",
              "[2250 rows x 717 columns]"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "oUYKNqPakFUM",
        "outputId": "213cff9f-5cd7-4cff-f198-c05b8122515a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4bcc53bf-8250-4c91-a61e-7512c2889265\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1192</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "      <th>alabels</th>\n",
              "      <th>blabels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>-1.625735</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>-0.114245</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.257091</td>\n",
              "      <td>-1.168413</td>\n",
              "      <td>0.223260</td>\n",
              "      <td>-0.482520</td>\n",
              "      <td>-0.085453</td>\n",
              "      <td>-0.382265</td>\n",
              "      <td>-0.539349</td>\n",
              "      <td>-1.682404</td>\n",
              "      <td>0.006326</td>\n",
              "      <td>0.004438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>0.513516</td>\n",
              "      <td>-0.099658</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>-0.000680</td>\n",
              "      <td>...</td>\n",
              "      <td>1.125450</td>\n",
              "      <td>-0.328047</td>\n",
              "      <td>-0.880305</td>\n",
              "      <td>-1.257607</td>\n",
              "      <td>0.964312</td>\n",
              "      <td>2.021104</td>\n",
              "      <td>0.655021</td>\n",
              "      <td>-0.423029</td>\n",
              "      <td>0.156763</td>\n",
              "      <td>0.008025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.904994</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>-0.086128</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.483701</td>\n",
              "      <td>-0.964782</td>\n",
              "      <td>-0.869555</td>\n",
              "      <td>0.066040</td>\n",
              "      <td>-0.444567</td>\n",
              "      <td>-0.531935</td>\n",
              "      <td>-0.878660</td>\n",
              "      <td>1.099488</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.034399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>-0.327977</td>\n",
              "      <td>1.226839</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>0.570237</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.763468</td>\n",
              "      <td>-0.789832</td>\n",
              "      <td>-0.113209</td>\n",
              "      <td>-2.703150</td>\n",
              "      <td>-2.058728</td>\n",
              "      <td>1.070627</td>\n",
              "      <td>-0.458045</td>\n",
              "      <td>-0.435825</td>\n",
              "      <td>0.089280</td>\n",
              "      <td>0.002526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>1.044211</td>\n",
              "      <td>0.518777</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>0.054435</td>\n",
              "      <td>...</td>\n",
              "      <td>0.711422</td>\n",
              "      <td>-0.190394</td>\n",
              "      <td>0.337224</td>\n",
              "      <td>-1.656639</td>\n",
              "      <td>0.707360</td>\n",
              "      <td>-0.562290</td>\n",
              "      <td>1.471181</td>\n",
              "      <td>-0.192000</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>0.002906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.319077</td>\n",
              "      <td>0.849589</td>\n",
              "      <td>0.822723</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.325704</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.910127</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>0.204808</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090717</td>\n",
              "      <td>-1.393713</td>\n",
              "      <td>-0.896694</td>\n",
              "      <td>-0.399675</td>\n",
              "      <td>-0.856395</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.863022</td>\n",
              "      <td>-0.601169</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>1.005737</td>\n",
              "      <td>-0.064755</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>0.724028</td>\n",
              "      <td>0.712760</td>\n",
              "      <td>-0.785929</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>1.107152</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.932417</td>\n",
              "      <td>-1.169053</td>\n",
              "      <td>-0.008414</td>\n",
              "      <td>-0.605636</td>\n",
              "      <td>-0.323927</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.315541</td>\n",
              "      <td>0.047928</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.002526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>1.252086</td>\n",
              "      <td>1.223561</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.987156</td>\n",
              "      <td>0.239435</td>\n",
              "      <td>-0.003031</td>\n",
              "      <td>-1.158309</td>\n",
              "      <td>1.237823</td>\n",
              "      <td>-1.272410</td>\n",
              "      <td>0.767154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>-1.243885</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.630589</td>\n",
              "      <td>1.594391</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>-1.429300</td>\n",
              "      <td>1.408976</td>\n",
              "      <td>0.999922</td>\n",
              "      <td>0.997274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>1.042624</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.066538</td>\n",
              "      <td>1.030667</td>\n",
              "      <td>1.162195</td>\n",
              "      <td>0.707827</td>\n",
              "      <td>-1.396612</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-1.025944</td>\n",
              "      <td>0.982839</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>-0.081338</td>\n",
              "      <td>-0.978116</td>\n",
              "      <td>-0.368307</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.090452</td>\n",
              "      <td>-1.444440</td>\n",
              "      <td>0.468686</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.002526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>-1.319572</td>\n",
              "      <td>-0.485173</td>\n",
              "      <td>-0.098500</td>\n",
              "      <td>2.323293</td>\n",
              "      <td>-0.139202</td>\n",
              "      <td>-0.953250</td>\n",
              "      <td>0.084661</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>1.427840</td>\n",
              "      <td>-0.403768</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.871845</td>\n",
              "      <td>0.654495</td>\n",
              "      <td>0.430631</td>\n",
              "      <td>-0.444470</td>\n",
              "      <td>-0.118851</td>\n",
              "      <td>0.471334</td>\n",
              "      <td>-0.078149</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>0.999936</td>\n",
              "      <td>0.631922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 1202 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bcc53bf-8250-4c91-a61e-7512c2889265')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bcc53bf-8250-4c91-a61e-7512c2889265 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bcc53bf-8250-4c91-a61e-7512c2889265');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
              "0    -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  1.243040   \n",
              "1    -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658 -1.124326   \n",
              "2     1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961 -0.495768   \n",
              "3     0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839 -0.085519   \n",
              "4     1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777 -0.298612   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2245  0.889888 -0.319077  0.849589  0.822723  0.876455  0.325704  0.876455   \n",
              "2246  1.005737 -0.064755  1.163494  1.163494  1.163494  0.724028  0.712760   \n",
              "2247  1.252086  1.223561  0.153859 -0.987156  0.239435 -0.003031 -1.158309   \n",
              "2248  1.042624 -0.129166  1.066538  1.030667  1.162195  0.707827 -1.396612   \n",
              "2249 -1.319572 -0.485173 -0.098500  2.323293 -0.139202 -0.953250  0.084661   \n",
              "\n",
              "           f_7       f_8       f_9  ...    f_1192    f_1193    f_1194  \\\n",
              "0     1.537751 -0.352028 -0.114245  ... -0.257091 -1.168413  0.223260   \n",
              "1     0.729430 -0.216224 -0.000680  ...  1.125450 -0.328047 -0.880305   \n",
              "2     0.060111 -1.418468 -0.086128  ... -0.483701 -0.964782 -0.869555   \n",
              "3     0.379008 -1.003667  0.570237  ... -0.763468 -0.789832 -0.113209   \n",
              "4    -0.365174  0.738447  0.054435  ...  0.711422 -0.190394  0.337224   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2245 -0.910127  0.889888  0.204808  ... -0.090717 -1.393713 -0.896694   \n",
              "2246 -0.785929 -1.225394  1.107152  ... -0.932417 -1.169053 -0.008414   \n",
              "2247  1.237823 -1.272410  0.767154  ...  0.809943 -1.243885  0.153859   \n",
              "2248  0.014319 -1.025944  0.982839  ...  0.086061 -0.081338 -0.978116   \n",
              "2249 -0.566577  1.427840 -0.403768  ... -0.871845  0.654495  0.430631   \n",
              "\n",
              "        f_1195    f_1196    f_1197    f_1198    f_1199   alabels   blabels  \n",
              "0    -0.482520 -0.085453 -0.382265 -0.539349 -1.682404  0.006326  0.004438  \n",
              "1    -1.257607  0.964312  2.021104  0.655021 -0.423029  0.156763  0.008025  \n",
              "2     0.066040 -0.444567 -0.531935 -0.878660  1.099488  0.002214  0.034399  \n",
              "3    -2.703150 -2.058728  1.070627 -0.458045 -0.435825  0.089280  0.002526  \n",
              "4    -1.656639  0.707360 -0.562290  1.471181 -0.192000  0.004455  0.002906  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2245 -0.399675 -0.856395  0.876455  0.863022 -0.601169  0.002214  0.000700  \n",
              "2246 -0.605636 -0.323927  1.163494 -1.315541  0.047928  0.002214  0.002526  \n",
              "2247 -0.630589  1.594391  1.252086 -1.429300  1.408976  0.999922  0.997274  \n",
              "2248 -0.368307 -0.129166  1.090452 -1.444440  0.468686  0.002214  0.002526  \n",
              "2249 -0.444470 -0.118851  0.471334 -0.078149 -0.566577  0.999936  0.631922  \n",
              "\n",
              "[2250 rows x 1202 columns]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOUKLx2OkFN4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P59niBpKppBy",
        "outputId": "5ab38e87-8af6-4ac7-a4c0-c360f8129a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 3ms/step\n",
            "71/71 [==============================] - 0s 4ms/step\n",
            "71/71 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "testdf['alabels'] = amodel.predict(sub2)\n",
        "# print()\n",
        "testdf['blabels'] = bmodel.predict(sub1)\n",
        "testdf['clabels'] = cmodel.predict(sub)\n",
        "\n",
        "# testdf['labels'] = testdf['labels'].apply(lambda x: 0 if x < .5 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "_WC71wGjlJYH",
        "outputId": "693ce30c-c259-4a06-cbd4-39202ff90260"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d278d1f8-f07f-4134-b777-5a277eae9393\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1193</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "      <th>alabels</th>\n",
              "      <th>blabels</th>\n",
              "      <th>clabels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>-1.625735</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.168413</td>\n",
              "      <td>0.223260</td>\n",
              "      <td>-0.482520</td>\n",
              "      <td>-0.085453</td>\n",
              "      <td>-0.382265</td>\n",
              "      <td>-0.539349</td>\n",
              "      <td>-1.682404</td>\n",
              "      <td>0.006326</td>\n",
              "      <td>0.004438</td>\n",
              "      <td>0.914955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>0.513516</td>\n",
              "      <td>-0.099658</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.328047</td>\n",
              "      <td>-0.880305</td>\n",
              "      <td>-1.257607</td>\n",
              "      <td>0.964312</td>\n",
              "      <td>2.021104</td>\n",
              "      <td>0.655021</td>\n",
              "      <td>-0.423029</td>\n",
              "      <td>0.156763</td>\n",
              "      <td>0.008025</td>\n",
              "      <td>0.022337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.904994</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.964782</td>\n",
              "      <td>-0.869555</td>\n",
              "      <td>0.066040</td>\n",
              "      <td>-0.444567</td>\n",
              "      <td>-0.531935</td>\n",
              "      <td>-0.878660</td>\n",
              "      <td>1.099488</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.034399</td>\n",
              "      <td>0.012494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>-0.327977</td>\n",
              "      <td>1.226839</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.789832</td>\n",
              "      <td>-0.113209</td>\n",
              "      <td>-2.703150</td>\n",
              "      <td>-2.058728</td>\n",
              "      <td>1.070627</td>\n",
              "      <td>-0.458045</td>\n",
              "      <td>-0.435825</td>\n",
              "      <td>0.089280</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.155510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>1.044211</td>\n",
              "      <td>0.518777</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.190394</td>\n",
              "      <td>0.337224</td>\n",
              "      <td>-1.656639</td>\n",
              "      <td>0.707360</td>\n",
              "      <td>-0.562290</td>\n",
              "      <td>1.471181</td>\n",
              "      <td>-0.192000</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>0.002906</td>\n",
              "      <td>0.040079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>2246</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.319077</td>\n",
              "      <td>0.849589</td>\n",
              "      <td>0.822723</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.325704</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.910127</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.393713</td>\n",
              "      <td>-0.896694</td>\n",
              "      <td>-0.399675</td>\n",
              "      <td>-0.856395</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.863022</td>\n",
              "      <td>-0.601169</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.000744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>2247</td>\n",
              "      <td>1.005737</td>\n",
              "      <td>-0.064755</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>0.724028</td>\n",
              "      <td>0.712760</td>\n",
              "      <td>-0.785929</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.169053</td>\n",
              "      <td>-0.008414</td>\n",
              "      <td>-0.605636</td>\n",
              "      <td>-0.323927</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.315541</td>\n",
              "      <td>0.047928</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.000588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>2248</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>1.223561</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.987156</td>\n",
              "      <td>0.239435</td>\n",
              "      <td>-0.003031</td>\n",
              "      <td>-1.158309</td>\n",
              "      <td>1.237823</td>\n",
              "      <td>-1.272410</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.243885</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.630589</td>\n",
              "      <td>1.594391</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>-1.429300</td>\n",
              "      <td>1.408976</td>\n",
              "      <td>0.999922</td>\n",
              "      <td>0.997274</td>\n",
              "      <td>0.990435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>2249</td>\n",
              "      <td>1.042624</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.066538</td>\n",
              "      <td>1.030667</td>\n",
              "      <td>1.162195</td>\n",
              "      <td>0.707827</td>\n",
              "      <td>-1.396612</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-1.025944</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.081338</td>\n",
              "      <td>-0.978116</td>\n",
              "      <td>-0.368307</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.090452</td>\n",
              "      <td>-1.444440</td>\n",
              "      <td>0.468686</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.001756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>2250</td>\n",
              "      <td>-1.319572</td>\n",
              "      <td>-0.485173</td>\n",
              "      <td>-0.098500</td>\n",
              "      <td>2.323293</td>\n",
              "      <td>-0.139202</td>\n",
              "      <td>-0.953250</td>\n",
              "      <td>0.084661</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>1.427840</td>\n",
              "      <td>...</td>\n",
              "      <td>0.654495</td>\n",
              "      <td>0.430631</td>\n",
              "      <td>-0.444470</td>\n",
              "      <td>-0.118851</td>\n",
              "      <td>0.471334</td>\n",
              "      <td>-0.078149</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>0.999936</td>\n",
              "      <td>0.631922</td>\n",
              "      <td>0.996899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 1204 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d278d1f8-f07f-4134-b777-5a277eae9393')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d278d1f8-f07f-4134-b777-5a277eae9393 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d278d1f8-f07f-4134-b777-5a277eae9393');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
              "0        1 -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761   \n",
              "1        2 -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658   \n",
              "2        3  1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961   \n",
              "3        4  0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839   \n",
              "4        5  1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777   \n",
              "...    ...       ...       ...       ...       ...       ...       ...   \n",
              "2245  2246  0.889888 -0.319077  0.849589  0.822723  0.876455  0.325704   \n",
              "2246  2247  1.005737 -0.064755  1.163494  1.163494  1.163494  0.724028   \n",
              "2247  2248  1.252086  1.223561  0.153859 -0.987156  0.239435 -0.003031   \n",
              "2248  2249  1.042624 -0.129166  1.066538  1.030667  1.162195  0.707827   \n",
              "2249  2250 -1.319572 -0.485173 -0.098500  2.323293 -0.139202 -0.953250   \n",
              "\n",
              "           f_6       f_7       f_8  ...    f_1193    f_1194    f_1195  \\\n",
              "0     1.243040  1.537751 -0.352028  ... -1.168413  0.223260 -0.482520   \n",
              "1    -1.124326  0.729430 -0.216224  ... -0.328047 -0.880305 -1.257607   \n",
              "2    -0.495768  0.060111 -1.418468  ... -0.964782 -0.869555  0.066040   \n",
              "3    -0.085519  0.379008 -1.003667  ... -0.789832 -0.113209 -2.703150   \n",
              "4    -0.298612 -0.365174  0.738447  ... -0.190394  0.337224 -1.656639   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2245  0.876455 -0.910127  0.889888  ... -1.393713 -0.896694 -0.399675   \n",
              "2246  0.712760 -0.785929 -1.225394  ... -1.169053 -0.008414 -0.605636   \n",
              "2247 -1.158309  1.237823 -1.272410  ... -1.243885  0.153859 -0.630589   \n",
              "2248 -1.396612  0.014319 -1.025944  ... -0.081338 -0.978116 -0.368307   \n",
              "2249  0.084661 -0.566577  1.427840  ...  0.654495  0.430631 -0.444470   \n",
              "\n",
              "        f_1196    f_1197    f_1198    f_1199   alabels   blabels   clabels  \n",
              "0    -0.085453 -0.382265 -0.539349 -1.682404  0.006326  0.004438  0.914955  \n",
              "1     0.964312  2.021104  0.655021 -0.423029  0.156763  0.008025  0.022337  \n",
              "2    -0.444567 -0.531935 -0.878660  1.099488  0.002214  0.034399  0.012494  \n",
              "3    -2.058728  1.070627 -0.458045 -0.435825  0.089280  0.002526  0.155510  \n",
              "4     0.707360 -0.562290  1.471181 -0.192000  0.004455  0.002906  0.040079  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2245 -0.856395  0.876455  0.863022 -0.601169  0.002214  0.000700  0.000744  \n",
              "2246 -0.323927  1.163494 -1.315541  0.047928  0.002214  0.002526  0.000588  \n",
              "2247  1.594391  1.252086 -1.429300  1.408976  0.999922  0.997274  0.990435  \n",
              "2248 -0.129166  1.090452 -1.444440  0.468686  0.002214  0.002526  0.001756  \n",
              "2249 -0.118851  0.471334 -0.078149 -0.566577  0.999936  0.631922  0.996899  \n",
              "\n",
              "[2250 rows x 1204 columns]"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrPJCy9Xqo1q"
      },
      "outputs": [],
      "source": [
        "from numpy import argmax\n",
        "from numpy import argmin\n",
        "from statistics import mean\n",
        "\n",
        "testdf['labels'] = testdf[['alabels', 'blabels', 'clabels']].apply(lambda x: min(x)\\\n",
        "                                if mean(x)<0.5 else \\\n",
        "                                max(x), axis=1)\n",
        "testdf['labels'] = testdf['labels'].apply(lambda x: 0 if x < 0.5 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "WmrypG21mcSA",
        "outputId": "dd8d6b0f-f9a9-4883-e833-4be5ff1b72ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb48d196-8820-4fb6-8f58-560614164f4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_1194</th>\n",
              "      <th>f_1195</th>\n",
              "      <th>f_1196</th>\n",
              "      <th>f_1197</th>\n",
              "      <th>f_1198</th>\n",
              "      <th>f_1199</th>\n",
              "      <th>alabels</th>\n",
              "      <th>blabels</th>\n",
              "      <th>clabels</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-3.388242</td>\n",
              "      <td>0.868285</td>\n",
              "      <td>-0.427619</td>\n",
              "      <td>-0.678964</td>\n",
              "      <td>-1.625735</td>\n",
              "      <td>0.262761</td>\n",
              "      <td>1.243040</td>\n",
              "      <td>1.537751</td>\n",
              "      <td>-0.352028</td>\n",
              "      <td>...</td>\n",
              "      <td>0.223260</td>\n",
              "      <td>-0.482520</td>\n",
              "      <td>-0.085453</td>\n",
              "      <td>-0.382265</td>\n",
              "      <td>-0.539349</td>\n",
              "      <td>-1.682404</td>\n",
              "      <td>0.006326</td>\n",
              "      <td>0.004438</td>\n",
              "      <td>0.914955</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.496920</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.989040</td>\n",
              "      <td>0.451422</td>\n",
              "      <td>0.513516</td>\n",
              "      <td>-0.099658</td>\n",
              "      <td>-1.124326</td>\n",
              "      <td>0.729430</td>\n",
              "      <td>-0.216224</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.880305</td>\n",
              "      <td>-1.257607</td>\n",
              "      <td>0.964312</td>\n",
              "      <td>2.021104</td>\n",
              "      <td>0.655021</td>\n",
              "      <td>-0.423029</td>\n",
              "      <td>0.156763</td>\n",
              "      <td>0.008025</td>\n",
              "      <td>0.022337</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.128369</td>\n",
              "      <td>-0.537951</td>\n",
              "      <td>2.544358</td>\n",
              "      <td>1.165254</td>\n",
              "      <td>-1.904994</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>-0.495768</td>\n",
              "      <td>0.060111</td>\n",
              "      <td>-1.418468</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.869555</td>\n",
              "      <td>0.066040</td>\n",
              "      <td>-0.444567</td>\n",
              "      <td>-0.531935</td>\n",
              "      <td>-0.878660</td>\n",
              "      <td>1.099488</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.034399</td>\n",
              "      <td>0.012494</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.051253</td>\n",
              "      <td>1.746814</td>\n",
              "      <td>0.681177</td>\n",
              "      <td>1.844524</td>\n",
              "      <td>-0.327977</td>\n",
              "      <td>1.226839</td>\n",
              "      <td>-0.085519</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>-1.003667</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.113209</td>\n",
              "      <td>-2.703150</td>\n",
              "      <td>-2.058728</td>\n",
              "      <td>1.070627</td>\n",
              "      <td>-0.458045</td>\n",
              "      <td>-0.435825</td>\n",
              "      <td>0.089280</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.155510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.423209</td>\n",
              "      <td>-0.983594</td>\n",
              "      <td>-1.694170</td>\n",
              "      <td>1.197507</td>\n",
              "      <td>1.044211</td>\n",
              "      <td>0.518777</td>\n",
              "      <td>-0.298612</td>\n",
              "      <td>-0.365174</td>\n",
              "      <td>0.738447</td>\n",
              "      <td>...</td>\n",
              "      <td>0.337224</td>\n",
              "      <td>-1.656639</td>\n",
              "      <td>0.707360</td>\n",
              "      <td>-0.562290</td>\n",
              "      <td>1.471181</td>\n",
              "      <td>-0.192000</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>0.002906</td>\n",
              "      <td>0.040079</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>2246</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>-0.319077</td>\n",
              "      <td>0.849589</td>\n",
              "      <td>0.822723</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.325704</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>-0.910127</td>\n",
              "      <td>0.889888</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.896694</td>\n",
              "      <td>-0.399675</td>\n",
              "      <td>-0.856395</td>\n",
              "      <td>0.876455</td>\n",
              "      <td>0.863022</td>\n",
              "      <td>-0.601169</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.000744</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>2247</td>\n",
              "      <td>1.005737</td>\n",
              "      <td>-0.064755</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>0.724028</td>\n",
              "      <td>0.712760</td>\n",
              "      <td>-0.785929</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008414</td>\n",
              "      <td>-0.605636</td>\n",
              "      <td>-0.323927</td>\n",
              "      <td>1.163494</td>\n",
              "      <td>-1.315541</td>\n",
              "      <td>0.047928</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.000588</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>2248</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>1.223561</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.987156</td>\n",
              "      <td>0.239435</td>\n",
              "      <td>-0.003031</td>\n",
              "      <td>-1.158309</td>\n",
              "      <td>1.237823</td>\n",
              "      <td>-1.272410</td>\n",
              "      <td>...</td>\n",
              "      <td>0.153859</td>\n",
              "      <td>-0.630589</td>\n",
              "      <td>1.594391</td>\n",
              "      <td>1.252086</td>\n",
              "      <td>-1.429300</td>\n",
              "      <td>1.408976</td>\n",
              "      <td>0.999922</td>\n",
              "      <td>0.997274</td>\n",
              "      <td>0.990435</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>2249</td>\n",
              "      <td>1.042624</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.066538</td>\n",
              "      <td>1.030667</td>\n",
              "      <td>1.162195</td>\n",
              "      <td>0.707827</td>\n",
              "      <td>-1.396612</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-1.025944</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.978116</td>\n",
              "      <td>-0.368307</td>\n",
              "      <td>-0.129166</td>\n",
              "      <td>1.090452</td>\n",
              "      <td>-1.444440</td>\n",
              "      <td>0.468686</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.001756</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>2250</td>\n",
              "      <td>-1.319572</td>\n",
              "      <td>-0.485173</td>\n",
              "      <td>-0.098500</td>\n",
              "      <td>2.323293</td>\n",
              "      <td>-0.139202</td>\n",
              "      <td>-0.953250</td>\n",
              "      <td>0.084661</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>1.427840</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430631</td>\n",
              "      <td>-0.444470</td>\n",
              "      <td>-0.118851</td>\n",
              "      <td>0.471334</td>\n",
              "      <td>-0.078149</td>\n",
              "      <td>-0.566577</td>\n",
              "      <td>0.999936</td>\n",
              "      <td>0.631922</td>\n",
              "      <td>0.996899</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 1205 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb48d196-8820-4fb6-8f58-560614164f4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb48d196-8820-4fb6-8f58-560614164f4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb48d196-8820-4fb6-8f58-560614164f4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
              "0        1 -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761   \n",
              "1        2 -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658   \n",
              "2        3  1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961   \n",
              "3        4  0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839   \n",
              "4        5  1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777   \n",
              "...    ...       ...       ...       ...       ...       ...       ...   \n",
              "2245  2246  0.889888 -0.319077  0.849589  0.822723  0.876455  0.325704   \n",
              "2246  2247  1.005737 -0.064755  1.163494  1.163494  1.163494  0.724028   \n",
              "2247  2248  1.252086  1.223561  0.153859 -0.987156  0.239435 -0.003031   \n",
              "2248  2249  1.042624 -0.129166  1.066538  1.030667  1.162195  0.707827   \n",
              "2249  2250 -1.319572 -0.485173 -0.098500  2.323293 -0.139202 -0.953250   \n",
              "\n",
              "           f_6       f_7       f_8  ...    f_1194    f_1195    f_1196  \\\n",
              "0     1.243040  1.537751 -0.352028  ...  0.223260 -0.482520 -0.085453   \n",
              "1    -1.124326  0.729430 -0.216224  ... -0.880305 -1.257607  0.964312   \n",
              "2    -0.495768  0.060111 -1.418468  ... -0.869555  0.066040 -0.444567   \n",
              "3    -0.085519  0.379008 -1.003667  ... -0.113209 -2.703150 -2.058728   \n",
              "4    -0.298612 -0.365174  0.738447  ...  0.337224 -1.656639  0.707360   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2245  0.876455 -0.910127  0.889888  ... -0.896694 -0.399675 -0.856395   \n",
              "2246  0.712760 -0.785929 -1.225394  ... -0.008414 -0.605636 -0.323927   \n",
              "2247 -1.158309  1.237823 -1.272410  ...  0.153859 -0.630589  1.594391   \n",
              "2248 -1.396612  0.014319 -1.025944  ... -0.978116 -0.368307 -0.129166   \n",
              "2249  0.084661 -0.566577  1.427840  ...  0.430631 -0.444470 -0.118851   \n",
              "\n",
              "        f_1197    f_1198    f_1199   alabels   blabels   clabels  labels  \n",
              "0    -0.382265 -0.539349 -1.682404  0.006326  0.004438  0.914955       0  \n",
              "1     2.021104  0.655021 -0.423029  0.156763  0.008025  0.022337       0  \n",
              "2    -0.531935 -0.878660  1.099488  0.002214  0.034399  0.012494       0  \n",
              "3     1.070627 -0.458045 -0.435825  0.089280  0.002526  0.155510       0  \n",
              "4    -0.562290  1.471181 -0.192000  0.004455  0.002906  0.040079       0  \n",
              "...        ...       ...       ...       ...       ...       ...     ...  \n",
              "2245  0.876455  0.863022 -0.601169  0.002214  0.000700  0.000744       0  \n",
              "2246  1.163494 -1.315541  0.047928  0.002214  0.002526  0.000588       0  \n",
              "2247  1.252086 -1.429300  1.408976  0.999922  0.997274  0.990435       1  \n",
              "2248  1.090452 -1.444440  0.468686  0.002214  0.002526  0.001756       0  \n",
              "2249  0.471334 -0.078149 -0.566577  0.999936  0.631922  0.996899       1  \n",
              "\n",
              "[2250 rows x 1205 columns]"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5IqmpsFqyC0"
      },
      "outputs": [],
      "source": [
        "submission = testdf[['id', 'labels']]\n",
        "\n",
        "submission.to_csv(\"NN_waug_ensemble.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vWCr7IoIrBQV",
        "outputId": "f8714951-ecaa-4969-a0d4-429a2ce0ac49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d88c5272-7efc-4885-9163-76f4462c19dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>2246</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>2247</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>2248</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>2249</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>2250</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2250 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d88c5272-7efc-4885-9163-76f4462c19dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d88c5272-7efc-4885-9163-76f4462c19dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d88c5272-7efc-4885-9163-76f4462c19dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id  labels\n",
              "0        1       0\n",
              "1        2       0\n",
              "2        3       0\n",
              "3        4       0\n",
              "4        5       0\n",
              "...    ...     ...\n",
              "2245  2246       0\n",
              "2246  2247       0\n",
              "2247  2248       1\n",
              "2248  2249       0\n",
              "2249  2250       1\n",
              "\n",
              "[2250 rows x 2 columns]"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy6Bkifbndnu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}